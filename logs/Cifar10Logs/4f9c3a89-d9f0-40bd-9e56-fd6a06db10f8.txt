====================================================================================================
# NOTE: record from https://github.com/KellerJordan/modded-nanogpt/blob/master/records/track_1_short/2024-10-14_ModernArch/dabaaddd-237c-4ec9-939d-6608a9ed5e27.txt
#====================================================================================================
import os
import sys
with open(sys.argv[0]) as f:
    code = f.read() # read the code of this file ASAP, for logging
import uuid
import glob
import time
from dataclasses import dataclass

import numpy as np
import torch
from torch import nn
import torch.nn.functional as F
import torch.distributed as dist
import torch._inductor.config as config
from torch.nn.parallel import DistributedDataParallel as DDP

# -----------------------------------------------------------------------------
# Muon optimizer

def zeropower_via_svd(G, steps=None):
    U, S, V = G.svd()
    return U @ V.T

@torch.compile
def zeropower_via_newtonschulz5(G, steps=10, eps=1e-7):
    """
    Newton-Schulz iteration to compute the zeroth power / orthogonalization of G. We opt to use a
    quintic iteration whose coefficients are selected to maximize the slope at zero. For the purpose
    of minimizing steps, it turns out to be empirically effective to keep increasing the slope at
    zero even beyond the point where the iteration no longer converges all the way to one everywhere
    on the interval. This iteration therefore does not produce UV^T but rather something like US'V^T
    where S' is diagonal with S_{ii}' \sim Uniform(0.5, 1.5), which turns out not to hurt model
    performance at all relative to UV^T, where USV^T = G is the SVD.
    """
    assert len(G.shape) == 2
    a, b, c = (3.4445, -4.7750,  2.0315)
    X = G.bfloat16()
    X /= (X.norm() + eps) # ensure top singular value <= 1
    if G.size(0) > G.size(1):
        X = X.T
    for _ in range(steps):
        A = X @ X.T
        B = A @ X
        X = a * X + b * B + c * A @ B
    if G.size(0) > G.size(1):
        X = X.T
    return X

zeropower_backends = dict(svd=zeropower_via_svd, newtonschulz5=zeropower_via_newtonschulz5)

class Muon(torch.optim.Optimizer):
    """
    Muon - MomentUm Orthogonalized by Newton-schulz

    Muon internally runs standard SGD-momentum, and then performs an orthogonalization post-
    processing step, in which each 2D parameter's update is replaced with the nearest orthogonal
    matrix. To efficiently orthogonalize each update, we use a Newton-Schulz iteration, which has
    the advantage that it can be stably run in bfloat16 on the GPU.

    Some warnings:
    - This optimizer assumes that all parameters passed in are 2D.
    - It should not be used for the embedding layer, the final fully connected layer, or any {0,1}-D
    parameters; those should all be optimized by a standard method (e.g., AdamW).
    - To use it with 4D convolutional filters, it works well to just flatten their last 3 dimensions.
    - We believe it is unlikely to work well for training with small batch size.
    - We believe it may not work well for finetuning pretrained models, but we haven't tested this.
    - We have not yet tried this optimizer for training scenarios larger than NanoGPT (124M).

    Arguments:
        lr: The learning rate used by the internal SGD.
        momentum: The momentum used by the internal SGD.
        nesterov: Whether to use Nesterov-style momentum in the internal SGD. (recommended)
        backend: The chosen backend for the orthogonalization step. (recommended: 'newtonschulz5')
        backend_steps: The number of iteration steps to use in the backend, if it is iterative.
    """
    def __init__(self, params, lr=3e-4, momentum=0.95, nesterov=True, backend='newtonschulz5', backend_steps=5):
        defaults = dict(lr=lr, momentum=momentum, nesterov=nesterov, backend=backend, backend_steps=backend_steps)
        super().__init__(params, defaults)

    def step(self):
        for group in self.param_groups:
            lr = group['lr']
            momentum = group['momentum']
            zeropower_backend = zeropower_backends[group['backend']]
            for p in group['params']:
                g = p.grad
                if g is None:
                    continue
                state = self.state[p]
                if 'momentum_buffer' not in state:
                    state['momentum_buffer'] = torch.zeros_like(g)
                buf = state['momentum_buffer']
                buf.mul_(momentum).add_(g)
                if group['nesterov']:
                    g = g.add(buf, alpha=momentum)
                if g.size(0) == 3 * g.size(1): # split grouped QKV parameters
                    g = torch.cat([zeropower_backend(g1, steps=group['backend_steps']) for g1 in g.split(g.size(1))])
                    scale = g.size(1)**0.5
                else:
                    g = zeropower_backend(g, steps=group['backend_steps'])
                    scale = max(g.size(0), g.size(1))**0.5 # scale to have update.square().mean() == 1
                p.data.add_(g, alpha=-lr * scale)

# -----------------------------------------------------------------------------
# PyTorch nn.Module definitions for the GPT-2 model

class Rotary(torch.nn.Module):

    def __init__(self, dim, base=10000):
        super().__init__()
        self.inv_freq = 1.0 / (base ** (torch.arange(0, dim, 2).float() / dim))
        self.seq_len_cached = None
        self.cos_cached = None
        self.sin_cached = None

    def forward(self, x):
        seq_len = x.shape[1]
        if seq_len != self.seq_len_cached:
            self.seq_len_cached = seq_len
            t = torch.arange(seq_len, device=x.device).type_as(self.inv_freq)
            freqs = torch.outer(t, self.inv_freq).to(x.device)
            self.cos_cached = freqs.cos().bfloat16()
            self.sin_cached = freqs.sin().bfloat16()
        return self.cos_cached[None, :, None, :], self.sin_cached[None, :, None, :]

def apply_rotary_emb(x, cos, sin):
    assert x.ndim == 4 # multihead attention
    d = x.shape[3]//2
    x1 = x[..., :d]
    x2 = x[..., d:]
    y1 = x1 * cos + x2 * sin
    y2 = x1 * (-sin) + x2 * cos
    return torch.cat([y1, y2], 3).type_as(x)

class CausalSelfAttention(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.n_head = config.n_head
        self.n_embd = config.n_embd
        self.head_dim = self.n_embd // self.n_head
        assert self.n_embd % self.n_head == 0
        self.c_q = nn.Linear(self.n_embd, self.n_embd, bias=False)
        self.c_k = nn.Linear(self.n_embd, self.n_embd, bias=False)
        self.c_v = nn.Linear(self.n_embd, self.n_embd, bias=False)
        # output projection
        self.c_proj = nn.Linear(self.n_embd, self.n_embd, bias=False)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977
        self.rotary = Rotary(self.head_dim)

    def forward(self, x):
        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)
        q = self.c_q(x).view(B, T, self.n_head, self.head_dim)
        k = self.c_k(x).view(B, T, self.n_head, self.head_dim)
        v = self.c_v(x).view(B, T, self.n_head, self.head_dim)
        cos, sin = self.rotary(q)
        q, k = apply_rotary_emb(q, cos, sin), apply_rotary_emb(k, cos, sin)
        q, k = F.rms_norm(q, (q.size(-1),)), F.rms_norm(k, (k.size(-1),)) # QK norm suggested by @Grad62304977
        y = F.scaled_dot_product_attention(q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2), is_causal=True)
        y = y.transpose(1, 2).contiguous().view_as(x) # re-assemble all head outputs side by side
        y = self.c_proj(y)
        return y

class MLP(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd, bias=False)
        self.c_proj  = nn.Linear(4 * config.n_embd, config.n_embd, bias=False)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977

    def forward(self, x):
        x = self.c_fc(x)
        x = F.relu(x).square() # https://arxiv.org/abs/2109.08668v2; ~1-2% better than GELU; suggested by @SKYLINEZ007 and @Grad62304977
        x = self.c_proj(x)
        return x

class Block(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.attn = CausalSelfAttention(config)
        self.mlp = MLP(config)

    def forward(self, x):
        x = x + self.attn(F.rms_norm(x, (x.size(-1),)))
        x = x + self.mlp(F.rms_norm(x, (x.size(-1),)))
        return x

# -----------------------------------------------------------------------------
# The main GPT-2 model

@dataclass
class GPTConfig:
    vocab_size : int = 50304
    n_layer : int = 12
    n_head : int = 6 # head dim 128 suggested by @Grad62304977
    n_embd : int = 768

class GPT(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.config = config

        self.transformer = nn.ModuleDict(dict(
            wte = nn.Embedding(config.vocab_size, config.n_embd),
            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),
        ))
        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)
        self.transformer.wte.weight = self.lm_head.weight # https://paperswithcode.com/method/weight-tying

    def forward(self, idx, targets=None, return_logits=True):

        # forward the GPT model itself
        x = self.transformer.wte(idx) # token embeddings of shape (b, t, n_embd)
        for block in self.transformer.h:
            x = block(x)
        x = F.rms_norm(x, (x.size(-1),))

        if targets is not None:
            # if we are given some desired targets also calculate the loss
            logits = self.lm_head(x)
            logits = logits.float() # use tf32/fp32 for logits
            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)
        else:
            # inference-time mini-optimization: only forward the lm_head on the very last position
            logits = self.lm_head(x[:, [-1], :]) # note: using list [-1] to preserve the time dim
            logits = logits.float() # use tf32/fp32 for logits
            loss = None

        # there are performance reasons why not returning logits is prudent, if not needed
        if not return_logits:
            logits = None

        return logits, loss

# -----------------------------------------------------------------------------
# Our own simple Distributed Data Loader

def _peek_data_shard(filename):
    # only reads the header, returns header data
    with open(filename, "rb") as f:
        # first read the header, which is 256 int32 integers (4 bytes each)
        header = np.frombuffer(f.read(256*4), dtype=np.int32)
    if header[0] != 20240520:
        print("ERROR: magic number mismatch in the data .bin file!")
        print("---> HINT: Are you passing in a correct file with --input_bin?")
        print("---> HINT: Dataset encoding changed recently, re-run data prepro or refer again to README")
        print("---> HINT: For example re-run: `python dev/data/tinyshakespeare.py`, then re-try")
        exit(1)
    assert header[1] == 1, "unsupported version"
    ntok = header[2] # number of tokens (claimed)
    return ntok # for now just return the number of tokens

def _load_data_shard(filename):
    with open(filename, "rb") as f:
        # first read the header, which is 256 int32 integers (4 bytes each)
        header = np.frombuffer(f.read(256*4), dtype=np.int32)
        assert header[0] == 20240520, "magic number mismatch in the data .bin file"
        assert header[1] == 1, "unsupported version"
        ntok = header[2] # number of tokens (claimed)
        # the rest of it are tokens, stored as uint16
        tokens = np.frombuffer(f.read(), dtype=np.uint16)
    assert len(tokens) == ntok, "number of tokens read does not match header?"
    return tokens

class DistributedDataLoader:
    def __init__(self, filename_pattern, B, T, process_rank, num_processes):
        self.process_rank = process_rank
        self.num_processes = num_processes
        self.B = B
        self.T = T

        # glob files that match the pattern
        self.files = sorted(glob.glob(filename_pattern))
        assert len(self.files) > 0, f"did not find any files that match the pattern {filename_pattern}"

        # load and validate all data shards, count number of tokens in total
        ntok_total = 0
        for fname in self.files:
            shard_ntok = _peek_data_shard(fname)
            assert shard_ntok >= num_processes * B * T + 1
            ntok_total += int(shard_ntok)
        self.ntok_total = ntok_total

        # kick things off
        self.reset()

    def reset(self):
        self.current_shard = 0
        self.current_position = self.process_rank * self.B * self.T
        self.tokens = _load_data_shard(self.files[self.current_shard])

    def advance(self): # advance to next data shard
        self.current_shard = (self.current_shard + 1) % len(self.files)
        self.current_position = self.process_rank * self.B * self.T
        self.tokens = _load_data_shard(self.files[self.current_shard])

    def next_batch(self):
        B = self.B
        T = self.T
        buf = self.tokens[self.current_position : self.current_position+B*T+1]
        buf = torch.tensor(buf.astype(np.int32), dtype=torch.long)
        x = (buf[:-1]).view(B, T) # inputs
        y = (buf[1:]).view(B, T) # targets
        # advance current position and load next shard if necessary
        self.current_position += B * T * self.num_processes
        if self.current_position + (B * T * self.num_processes + 1) > len(self.tokens):
            self.advance()
        return x.cuda(), y.cuda()

# -----------------------------------------------------------------------------
# int main

@dataclass
class Hyperparameters:
    # data hyperparams
    input_bin : str = 'data/fineweb10B/fineweb_train_*.bin' # input .bin to train on
    input_val_bin : str = 'data/fineweb10B/fineweb_val_*.bin' # input .bin to eval validation loss on
    # optimization hyperparams
    batch_size : int = 8*64 # batch size, in sequences, across all devices
    device_batch_size : int = 64 # batch size, in sequences, per device
    sequence_length : int = 1024 # sequence length, in tokens
    num_iterations : int = 5100 # number of iterations to run
    learning_rate : float = 0.0036
    warmup_iters : int = 0
    warmdown_iters : int = 1450 # number of iterations of linear warmup/warmdown for triangular or trapezoidal schedule
    weight_decay : float = 0
    # evaluation and logging hyperparams
    val_loss_every : int = 125 # every how many steps to evaluate val loss? 0 for only at the end
    val_tokens : int = 10485760 # how many tokens of validation data? it's important to keep this fixed for consistent comparisons
    save_every : int = 0 # every how many steps to save the checkpoint? 0 for only at the end
args = Hyperparameters()

# set up DDP (distributed data parallel). torchrun sets this env variable
assert torch.cuda.is_available()
dist.init_process_group(backend='nccl')
ddp_rank = int(os.environ['RANK'])
ddp_local_rank = int(os.environ['LOCAL_RANK'])
ddp_world_size = int(os.environ['WORLD_SIZE'])
device = f'cuda:{ddp_local_rank}'
torch.cuda.set_device(device)
print(f"using device: {device}")
master_process = (ddp_rank == 0) # this process will do logging, checkpointing etc.

# convenience variables
B, T = args.device_batch_size, args.sequence_length
# calculate the number of steps to take in the val loop.
assert args.val_tokens % (B * T * ddp_world_size) == 0
val_steps = args.val_tokens // (B * T * ddp_world_size)
# calculate the steps of gradient accumulation required to attain the desired global batch size.
assert args.batch_size % (B * ddp_world_size) == 0
train_accumulation_steps = args.batch_size // (B * ddp_world_size)

# load tokens
train_loader = DistributedDataLoader(args.input_bin, B, T, ddp_rank, ddp_world_size)
val_loader = DistributedDataLoader(args.input_val_bin, B, T, ddp_rank, ddp_world_size)
if master_process:
    print(f"Training DataLoader: total number of tokens: {train_loader.ntok_total} across {len(train_loader.files)} files")
    print(f"Validation DataLoader: total number of tokens: {val_loader.ntok_total} across {len(val_loader.files)} files")
x, y = train_loader.next_batch()

# there are only 50257 unique GPT-2 tokens; we extend to nearest multiple of 128 for efficiency. suggested to me by @Grad62304977.
# this originates from Karpathy's experiments.
num_vocab = 50304
model = GPT(GPTConfig(vocab_size=num_vocab, n_layer=12, n_head=6, n_embd=768))
model = model.cuda()
if hasattr(config, "coordinate_descent_tuning"):
    config.coordinate_descent_tuning = True # suggested by @Chillee
model = torch.compile(model)
# here we wrap model into DDP container
model = DDP(model, device_ids=[ddp_local_rank])
raw_model = model.module # always contains the "raw" unwrapped model
ctx = torch.amp.autocast(device_type='cuda', dtype=torch.bfloat16)

# init the optimizer(s)
optimizer1 = torch.optim.AdamW(raw_model.lm_head.parameters(), lr=args.learning_rate, betas=(0.9, 0.95),
                               weight_decay=args.weight_decay, fused=True)
optimizer2 = Muon(raw_model.transformer.h.parameters(), lr=0.1*args.learning_rate, momentum=0.95)
optimizers = [optimizer1, optimizer2]
# learning rate decay scheduler (linear warmup and warmdown)
def get_lr(it):
    assert it <= args.num_iterations
    # 1) linear warmup for warmup_iters steps
    if it < args.warmup_iters:
        return (it+1) / args.warmup_iters
    # 2) constant lr for a while
    elif it < args.num_iterations - args.warmdown_iters:
        return 1.0
    # 3) linear warmdown
    else:
        decay_ratio = (args.num_iterations - it) / args.warmdown_iters
        return decay_ratio
schedulers = [torch.optim.lr_scheduler.LambdaLR(opt, get_lr) for opt in optimizers]

# begin logging
if master_process:
    run_id = str(uuid.uuid4())
    logdir = 'logs/%s/' % run_id
    os.makedirs(logdir, exist_ok=True)
    logfile = 'logs/%s.txt' % run_id
    # create the log file
    with open(logfile, "w") as f:
        # begin the log by printing this file (the Python code)
        f.write('='*100 + '\n')
        f.write(code)
        f.write('='*100 + '\n')
        # log information about the hardware/software environment this is running on
        # and print the full `nvidia-smi` to file
        f.write(f"Running pytorch {torch.version.__version__} compiled for CUDA {torch.version.cuda}\nnvidia-smi:\n")
        import subprocess
        result = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
        f.write(f'{result.stdout}\n')
        f.write('='*100 + '\n')

training_time_ms = 0
# start the clock
torch.cuda.synchronize()
t0 = time.time()
# begin training
train_loader.reset()
for step in range(args.num_iterations + 1):
    last_step = (step == args.num_iterations)
    # This effectively ignores timing first 10 steps, which are slower for weird reasons.
    # Alternately, and slightly more correctly in terms of benchmarking, we could do 10
    # steps with dummy data first, and then re-initialize the model and reset the loader.
    if step == 10:
        training_time_ms = 0
        t0 = time.time()
    timed_steps = float('nan') if step <= 11 else (step - 10) + 1 # <= 11 to avoid bug in val

    # once in a while evaluate the validation dataset
    if (last_step or (args.val_loss_every > 0 and step % args.val_loss_every == 0)):
        # stop the clock
        torch.cuda.synchronize()
        training_time_ms += 1000 * (time.time() - t0)
        # run validation batches
        model.eval()
        val_loader.reset()
        val_loss = 0.0
        for _ in range(val_steps):
            x_val, y_val = val_loader.next_batch()
            with ctx: # of course, we'd like to use no_grad() here too, but that creates a torch.compile error for some reason
                _, loss = model(x_val, y_val, return_logits=False)
                val_loss += loss.detach()
                del loss
        dist.all_reduce(val_loss, op=dist.ReduceOp.AVG)
        val_loss /= val_steps
        # log val loss to console and to logfile
        if master_process:
            print(f'step:{step}/{args.num_iterations} val_loss:{val_loss:.4f} train_time:{training_time_ms:.0f}ms step_avg:{training_time_ms/(timed_steps-1):.2f}ms')
            with open(logfile, "a") as f:
                f.write(f'step:{step}/{args.num_iterations} val_loss:{val_loss:.4f} train_time:{training_time_ms:.0f}ms step_avg:{training_time_ms/(timed_steps-1):.2f}ms\n')
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.time()

    if master_process and (last_step or (args.save_every > 0 and step % args.save_every == 0)):
        # stop the clock
        torch.cuda.synchronize()
        training_time_ms += 1000 * (time.time() - t0)
        # save the state of the training process
        log = dict(step=step, code=code, model=raw_model.state_dict(), optimizers=[opt.state_dict() for opt in optimizers])
        torch.save(log, 'logs/%s/state_step%06d.pt' % (run_id, step))
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.time()

    # bit confusing: we want to make sure to eval on 0th iteration
    # but also after the very last iteration. so we loop for step <= num_iterations
    # instead of just < num_iterations (one extra due to <=), only to do
    # the validation/sampling one last time, and then we break right here as we're done.
    if last_step:
        break

    # --------------- TRAINING SECTION BEGIN -----------------
    model.train()
    for i in range(1, train_accumulation_steps+1):
        # forward pass
        with ctx:
            _, loss = model(x, y, return_logits=False)
            train_loss = loss.detach()
        # advance the dataset for the next batch
        x, y = train_loader.next_batch()
        # backward pass
        if i < train_accumulation_steps:
            with model.no_sync(): # there's no need to sync gradients every accumulation step
                loss.backward()
        else:
            loss.backward() # just sync on the last step
    for p in model.parameters():
        p.grad /= train_accumulation_steps
    # step the optimizers and schedulers
    for opt, sched in zip(optimizers, schedulers):
        opt.step()
        sched.step()
    # null the gradients
    model.zero_grad(set_to_none=True)
    # --------------- TRAINING SECTION END -------------------
    # everything that follows now is just diagnostics, prints, logging, etc.

    #dist.all_reduce(train_loss, op=dist.ReduceOp.AVG) # all-reducing the training loss would be more correct in terms of logging, but slower
    if master_process:
        approx_time = training_time_ms + 1000 * (time.time() - t0)
        print(f"step:{step+1}/{args.num_iterations} train_loss:{train_loss.item():.4f} train_time:{approx_time:.0f}ms step_avg:{approx_time/timed_steps:.2f}ms")
        with open(logfile, "a") as f:
            f.write(f"step:{step+1}/{args.num_iterations} train_loss:{train_loss.item():.4f} train_time:{approx_time:.0f}ms step_avg:{approx_time/timed_steps:.2f}ms\n")

if master_process:
    print(f"peak memory consumption: {torch.cuda.max_memory_allocated() // 1024 // 1024} MiB")
====================================================================================================
Running pytorch 2.8.0+cu128 compiled for CUDA 12.8
nvidia-smi:
Sun Dec  7 01:14:56 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.195.03             Driver Version: 570.195.03     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100 80GB PCIe          On  |   00000000:00:07.0 Off |                    0 |
| N/A   39C    P0            100W /  300W |    2105MiB /  81920MiB |     44%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA A100 80GB PCIe          On  |   00000000:00:08.0 Off |                    0 |
| N/A   38C    P0            104W /  300W |    2105MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA A100 80GB PCIe          On  |   00000000:00:09.0 Off |                    0 |
| N/A   40C    P0            102W /  300W |    2105MiB /  81920MiB |     11%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA A100 80GB PCIe          On  |   00000000:00:0A.0 Off |                    0 |
| N/A   38C    P0            101W /  300W |    2105MiB /  81920MiB |      1%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   4  NVIDIA A100 80GB PCIe          On  |   00000000:00:0B.0 Off |                    0 |
| N/A   36C    P0            100W /  300W |    2105MiB /  81920MiB |     17%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   5  NVIDIA A100 80GB PCIe          On  |   00000000:00:0C.0 Off |                    0 |
| N/A   39C    P0            106W /  300W |    2105MiB /  81920MiB |     43%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   6  NVIDIA A100 80GB PCIe          On  |   00000000:00:0D.0 Off |                    0 |
| N/A   38C    P0             98W /  300W |    2105MiB /  81920MiB |     70%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   7  NVIDIA A100 80GB PCIe          On  |   00000000:00:0E.0 Off |                    0 |
| N/A   37C    P0             98W /  300W |    2105MiB /  81920MiB |     72%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
+-----------------------------------------------------------------------------------------+

====================================================================================================
step:0/5100 val_loss:16.0126 train_time:287ms step_avg:nanms
step:1/5100 train_loss:16.0078 train_time:84989ms step_avg:nanms
step:2/5100 train_loss:9.5331 train_time:87347ms step_avg:nanms
step:3/5100 train_loss:8.6647 train_time:88335ms step_avg:nanms
step:4/5100 train_loss:7.9754 train_time:89339ms step_avg:nanms
step:5/5100 train_loss:7.6047 train_time:90327ms step_avg:nanms
step:6/5100 train_loss:7.5317 train_time:91328ms step_avg:nanms
step:7/5100 train_loss:7.0804 train_time:92316ms step_avg:nanms
step:8/5100 train_loss:7.4101 train_time:93343ms step_avg:nanms
step:9/5100 train_loss:7.2421 train_time:94483ms step_avg:nanms
step:10/5100 train_loss:6.9232 train_time:95487ms step_avg:nanms
step:11/5100 train_loss:6.8933 train_time:981ms step_avg:nanms
step:12/5100 train_loss:6.9979 train_time:1973ms step_avg:nanms
step:13/5100 train_loss:6.6442 train_time:2958ms step_avg:986.04ms
step:14/5100 train_loss:6.6456 train_time:3974ms step_avg:993.51ms
step:15/5100 train_loss:6.5842 train_time:4993ms step_avg:998.64ms
step:16/5100 train_loss:6.5091 train_time:6016ms step_avg:1002.74ms
step:17/5100 train_loss:6.5169 train_time:7011ms step_avg:1001.51ms
step:18/5100 train_loss:6.5457 train_time:8000ms step_avg:1000.03ms
step:19/5100 train_loss:6.3760 train_time:9017ms step_avg:1001.94ms
step:20/5100 train_loss:6.4053 train_time:10032ms step_avg:1003.21ms
step:21/5100 train_loss:6.0647 train_time:11030ms step_avg:1002.75ms
step:22/5100 train_loss:6.4283 train_time:12045ms step_avg:1003.71ms
step:23/5100 train_loss:6.6446 train_time:13031ms step_avg:1002.35ms
step:24/5100 train_loss:6.3263 train_time:14010ms step_avg:1000.69ms
step:25/5100 train_loss:6.4505 train_time:14993ms step_avg:999.52ms
step:26/5100 train_loss:6.1640 train_time:15982ms step_avg:998.85ms
step:27/5100 train_loss:6.0818 train_time:16973ms step_avg:998.41ms
step:28/5100 train_loss:6.2177 train_time:17992ms step_avg:999.53ms
step:29/5100 train_loss:5.9041 train_time:19010ms step_avg:1000.55ms
step:30/5100 train_loss:6.1870 train_time:20020ms step_avg:1000.99ms
step:31/5100 train_loss:6.0211 train_time:21010ms step_avg:1000.46ms
step:32/5100 train_loss:5.9860 train_time:22002ms step_avg:1000.07ms
step:33/5100 train_loss:5.8200 train_time:22975ms step_avg:998.90ms
step:34/5100 train_loss:6.0943 train_time:23936ms step_avg:997.35ms
step:35/5100 train_loss:6.0291 train_time:24940ms step_avg:997.60ms
step:36/5100 train_loss:6.1807 train_time:25914ms step_avg:996.69ms
step:37/5100 train_loss:6.1168 train_time:26882ms step_avg:995.64ms
step:38/5100 train_loss:6.0142 train_time:27865ms step_avg:995.18ms
step:39/5100 train_loss:5.8978 train_time:28854ms step_avg:994.96ms
step:40/5100 train_loss:5.9161 train_time:29825ms step_avg:994.18ms
step:41/5100 train_loss:5.8286 train_time:30803ms step_avg:993.65ms
step:42/5100 train_loss:5.8524 train_time:31801ms step_avg:993.77ms
step:43/5100 train_loss:5.7338 train_time:32817ms step_avg:994.45ms
step:44/5100 train_loss:5.8327 train_time:33807ms step_avg:994.32ms
step:45/5100 train_loss:5.7907 train_time:34838ms step_avg:995.37ms
step:46/5100 train_loss:5.9482 train_time:35848ms step_avg:995.77ms
step:47/5100 train_loss:5.7379 train_time:36827ms step_avg:995.33ms
step:48/5100 train_loss:5.6159 train_time:37807ms step_avg:994.93ms
step:49/5100 train_loss:5.8234 train_time:38784ms step_avg:994.45ms
step:50/5100 train_loss:5.7096 train_time:39755ms step_avg:993.87ms
step:51/5100 train_loss:5.8457 train_time:40737ms step_avg:993.58ms
step:52/5100 train_loss:5.7124 train_time:41744ms step_avg:993.90ms
step:53/5100 train_loss:5.5722 train_time:42710ms step_avg:993.25ms
step:54/5100 train_loss:5.7088 train_time:43689ms step_avg:992.93ms
step:55/5100 train_loss:5.5964 train_time:44680ms step_avg:992.88ms
step:56/5100 train_loss:5.9330 train_time:45700ms step_avg:993.48ms
step:57/5100 train_loss:5.5861 train_time:46687ms step_avg:993.34ms
step:58/5100 train_loss:5.4529 train_time:47718ms step_avg:994.13ms
step:59/5100 train_loss:5.6100 train_time:48747ms step_avg:994.83ms
step:60/5100 train_loss:5.5773 train_time:49732ms step_avg:994.64ms
step:61/5100 train_loss:5.6580 train_time:50755ms step_avg:995.19ms
step:62/5100 train_loss:5.4370 train_time:51788ms step_avg:995.93ms
step:63/5100 train_loss:5.5430 train_time:52825ms step_avg:996.71ms
step:64/5100 train_loss:5.5156 train_time:53818ms step_avg:996.63ms
step:65/5100 train_loss:5.2200 train_time:54828ms step_avg:996.87ms
step:66/5100 train_loss:5.3335 train_time:55833ms step_avg:997.02ms
step:67/5100 train_loss:5.4850 train_time:56822ms step_avg:996.87ms
step:68/5100 train_loss:5.3622 train_time:57845ms step_avg:997.33ms
step:69/5100 train_loss:5.6240 train_time:58838ms step_avg:997.25ms
step:70/5100 train_loss:5.2654 train_time:59851ms step_avg:997.51ms
step:71/5100 train_loss:5.2954 train_time:60866ms step_avg:997.81ms
step:72/5100 train_loss:5.4954 train_time:61894ms step_avg:998.29ms
step:73/5100 train_loss:5.4285 train_time:62923ms step_avg:998.78ms
step:74/5100 train_loss:5.3072 train_time:63944ms step_avg:999.13ms
step:75/5100 train_loss:5.4293 train_time:64989ms step_avg:999.84ms
step:76/5100 train_loss:5.4060 train_time:66022ms step_avg:1000.34ms
step:77/5100 train_loss:5.3532 train_time:67054ms step_avg:1000.80ms
step:78/5100 train_loss:5.4577 train_time:68089ms step_avg:1001.31ms
step:79/5100 train_loss:5.5148 train_time:69093ms step_avg:1001.34ms
step:80/5100 train_loss:5.3062 train_time:70098ms step_avg:1001.39ms
step:81/5100 train_loss:5.4135 train_time:71100ms step_avg:1001.40ms
step:82/5100 train_loss:5.1797 train_time:72160ms step_avg:1002.22ms
step:83/5100 train_loss:5.3561 train_time:73182ms step_avg:1002.50ms
step:84/5100 train_loss:5.3059 train_time:74204ms step_avg:1002.75ms
step:85/5100 train_loss:5.2759 train_time:75204ms step_avg:1002.72ms
step:86/5100 train_loss:5.1449 train_time:76229ms step_avg:1003.01ms
step:87/5100 train_loss:5.3638 train_time:77230ms step_avg:1002.99ms
step:88/5100 train_loss:5.2706 train_time:78260ms step_avg:1003.33ms
step:89/5100 train_loss:5.3149 train_time:79272ms step_avg:1003.44ms
step:90/5100 train_loss:5.2665 train_time:80315ms step_avg:1003.94ms
step:91/5100 train_loss:5.2078 train_time:81337ms step_avg:1004.16ms
step:92/5100 train_loss:5.1745 train_time:82364ms step_avg:1004.44ms
step:93/5100 train_loss:5.3277 train_time:83397ms step_avg:1004.78ms
step:94/5100 train_loss:5.1288 train_time:84393ms step_avg:1004.68ms
step:95/5100 train_loss:5.1528 train_time:85398ms step_avg:1004.69ms
step:96/5100 train_loss:5.1882 train_time:86426ms step_avg:1004.95ms
step:97/5100 train_loss:5.1029 train_time:87440ms step_avg:1005.06ms
step:98/5100 train_loss:5.1857 train_time:88463ms step_avg:1005.27ms
step:99/5100 train_loss:5.1048 train_time:89458ms step_avg:1005.15ms
step:100/5100 train_loss:5.2214 train_time:90484ms step_avg:1005.38ms
step:101/5100 train_loss:5.1965 train_time:91483ms step_avg:1005.31ms
step:102/5100 train_loss:5.0982 train_time:92512ms step_avg:1005.57ms
step:103/5100 train_loss:5.2035 train_time:93547ms step_avg:1005.88ms
step:104/5100 train_loss:5.1479 train_time:94557ms step_avg:1005.93ms
step:105/5100 train_loss:5.0024 train_time:95582ms step_avg:1006.13ms
step:106/5100 train_loss:5.1002 train_time:96598ms step_avg:1006.23ms
step:107/5100 train_loss:5.2898 train_time:97644ms step_avg:1006.63ms
step:108/5100 train_loss:5.0817 train_time:98697ms step_avg:1007.12ms
step:109/5100 train_loss:4.8596 train_time:99761ms step_avg:1007.69ms
step:110/5100 train_loss:5.0421 train_time:100817ms step_avg:1008.17ms
step:111/5100 train_loss:5.0316 train_time:101839ms step_avg:1008.30ms
step:112/5100 train_loss:4.9905 train_time:102898ms step_avg:1008.80ms
step:113/5100 train_loss:5.1052 train_time:103918ms step_avg:1008.92ms
step:114/5100 train_loss:5.0288 train_time:104961ms step_avg:1009.24ms
step:115/5100 train_loss:4.8865 train_time:105990ms step_avg:1009.43ms
step:116/5100 train_loss:5.0429 train_time:107007ms step_avg:1009.50ms
step:117/5100 train_loss:4.9509 train_time:108052ms step_avg:1009.83ms
step:118/5100 train_loss:4.8991 train_time:109051ms step_avg:1009.73ms
step:119/5100 train_loss:5.0515 train_time:110067ms step_avg:1009.79ms
step:120/5100 train_loss:5.0050 train_time:111085ms step_avg:1009.86ms
step:121/5100 train_loss:4.9439 train_time:112125ms step_avg:1010.14ms
step:122/5100 train_loss:4.8276 train_time:113154ms step_avg:1010.31ms
step:123/5100 train_loss:4.9605 train_time:114170ms step_avg:1010.35ms
step:124/5100 train_loss:4.7906 train_time:115174ms step_avg:1010.30ms
step:125/5100 train_loss:5.1227 train_time:116226ms step_avg:1010.66ms
step:125/5100 val_loss:4.9517 train_time:116226ms step_avg:1010.66ms
step:126/5100 train_loss:4.9988 train_time:117217ms step_avg:1010.49ms
step:127/5100 train_loss:4.9447 train_time:118251ms step_avg:1010.70ms
step:128/5100 train_loss:5.0093 train_time:119293ms step_avg:1010.96ms
step:129/5100 train_loss:4.8715 train_time:120313ms step_avg:1011.03ms
step:130/5100 train_loss:5.1873 train_time:121335ms step_avg:1011.12ms
step:131/5100 train_loss:4.9355 train_time:122346ms step_avg:1011.12ms
step:132/5100 train_loss:4.9408 train_time:123390ms step_avg:1011.40ms
step:133/5100 train_loss:4.8960 train_time:124404ms step_avg:1011.42ms
step:134/5100 train_loss:4.9287 train_time:125451ms step_avg:1011.70ms
step:135/5100 train_loss:4.8215 train_time:126481ms step_avg:1011.85ms
step:136/5100 train_loss:4.9538 train_time:127487ms step_avg:1011.80ms
step:137/5100 train_loss:4.7194 train_time:128442ms step_avg:1011.35ms
step:138/5100 train_loss:4.8764 train_time:129451ms step_avg:1011.34ms
step:139/5100 train_loss:4.8285 train_time:130475ms step_avg:1011.43ms
step:140/5100 train_loss:4.8612 train_time:131479ms step_avg:1011.37ms
step:141/5100 train_loss:4.9157 train_time:132469ms step_avg:1011.22ms
step:142/5100 train_loss:4.8013 train_time:133453ms step_avg:1011.01ms
step:143/5100 train_loss:4.8589 train_time:134486ms step_avg:1011.18ms
step:144/5100 train_loss:4.7252 train_time:135499ms step_avg:1011.18ms
step:145/5100 train_loss:4.8546 train_time:136508ms step_avg:1011.17ms
step:146/5100 train_loss:4.8095 train_time:137510ms step_avg:1011.10ms
step:147/5100 train_loss:4.6828 train_time:138519ms step_avg:1011.09ms
step:148/5100 train_loss:4.8313 train_time:139529ms step_avg:1011.08ms
step:149/5100 train_loss:4.8321 train_time:140545ms step_avg:1011.12ms
step:150/5100 train_loss:4.8544 train_time:141546ms step_avg:1011.04ms
step:151/5100 train_loss:4.8973 train_time:142547ms step_avg:1010.97ms
step:152/5100 train_loss:4.7782 train_time:143526ms step_avg:1010.75ms
step:153/5100 train_loss:4.7804 train_time:144520ms step_avg:1010.63ms
step:154/5100 train_loss:4.8641 train_time:145557ms step_avg:1010.81ms
step:155/5100 train_loss:4.8220 train_time:146572ms step_avg:1010.84ms
step:156/5100 train_loss:4.7789 train_time:147573ms step_avg:1010.77ms
step:157/5100 train_loss:4.8042 train_time:148567ms step_avg:1010.66ms
step:158/5100 train_loss:4.9196 train_time:149591ms step_avg:1010.75ms
step:159/5100 train_loss:4.7064 train_time:150602ms step_avg:1010.75ms
step:160/5100 train_loss:4.7796 train_time:151595ms step_avg:1010.63ms
step:161/5100 train_loss:4.6135 train_time:152616ms step_avg:1010.70ms
step:162/5100 train_loss:4.8012 train_time:153627ms step_avg:1010.71ms
step:163/5100 train_loss:4.8257 train_time:154618ms step_avg:1010.58ms
step:164/5100 train_loss:4.8173 train_time:155627ms step_avg:1010.56ms
step:165/5100 train_loss:4.6264 train_time:156620ms step_avg:1010.45ms
step:166/5100 train_loss:4.7473 train_time:157603ms step_avg:1010.28ms
step:167/5100 train_loss:4.8881 train_time:158590ms step_avg:1010.13ms
step:168/5100 train_loss:4.6701 train_time:159543ms step_avg:1009.76ms
step:169/5100 train_loss:4.7682 train_time:160549ms step_avg:1009.74ms
step:170/5100 train_loss:4.6190 train_time:161562ms step_avg:1009.76ms
step:171/5100 train_loss:4.5196 train_time:162576ms step_avg:1009.79ms
step:172/5100 train_loss:4.6824 train_time:163586ms step_avg:1009.79ms
step:173/5100 train_loss:4.6655 train_time:164609ms step_avg:1009.87ms
step:174/5100 train_loss:4.7170 train_time:165606ms step_avg:1009.79ms
step:175/5100 train_loss:4.8677 train_time:166597ms step_avg:1009.68ms
step:176/5100 train_loss:4.7196 train_time:167584ms step_avg:1009.54ms
step:177/5100 train_loss:4.5692 train_time:168600ms step_avg:1009.58ms
step:178/5100 train_loss:4.5371 train_time:169605ms step_avg:1009.56ms
step:179/5100 train_loss:4.6158 train_time:170604ms step_avg:1009.49ms
step:180/5100 train_loss:4.6128 train_time:171593ms step_avg:1009.37ms
step:181/5100 train_loss:4.6138 train_time:172587ms step_avg:1009.28ms
step:182/5100 train_loss:4.7449 train_time:173588ms step_avg:1009.23ms
step:183/5100 train_loss:4.6098 train_time:174562ms step_avg:1009.03ms
step:184/5100 train_loss:4.5589 train_time:175608ms step_avg:1009.24ms
step:185/5100 train_loss:4.5719 train_time:176606ms step_avg:1009.18ms
step:186/5100 train_loss:4.6850 train_time:177634ms step_avg:1009.28ms
step:187/5100 train_loss:4.6103 train_time:178667ms step_avg:1009.42ms
step:188/5100 train_loss:4.7943 train_time:179677ms step_avg:1009.42ms
step:189/5100 train_loss:4.6235 train_time:180916ms step_avg:1010.70ms
step:190/5100 train_loss:4.5396 train_time:182181ms step_avg:1012.12ms
step:191/5100 train_loss:4.6789 train_time:183183ms step_avg:1012.06ms
step:192/5100 train_loss:4.5320 train_time:184161ms step_avg:1011.87ms
step:193/5100 train_loss:4.4633 train_time:185165ms step_avg:1011.83ms
step:194/5100 train_loss:4.6844 train_time:186127ms step_avg:1011.56ms
step:195/5100 train_loss:4.6004 train_time:187133ms step_avg:1011.53ms
step:196/5100 train_loss:4.7967 train_time:188151ms step_avg:1011.56ms
step:197/5100 train_loss:4.6485 train_time:189173ms step_avg:1011.62ms
step:198/5100 train_loss:4.5090 train_time:190162ms step_avg:1011.50ms
step:199/5100 train_loss:4.5783 train_time:191155ms step_avg:1011.40ms
step:200/5100 train_loss:4.4347 train_time:192135ms step_avg:1011.24ms
step:201/5100 train_loss:4.5336 train_time:193136ms step_avg:1011.18ms
step:202/5100 train_loss:4.4389 train_time:194128ms step_avg:1011.09ms
step:203/5100 train_loss:4.6881 train_time:195110ms step_avg:1010.93ms
step:204/5100 train_loss:4.5380 train_time:196098ms step_avg:1010.82ms
step:205/5100 train_loss:4.5800 train_time:197110ms step_avg:1010.82ms
step:206/5100 train_loss:4.6819 train_time:198120ms step_avg:1010.81ms
step:207/5100 train_loss:4.3495 train_time:199132ms step_avg:1010.82ms
step:208/5100 train_loss:4.5081 train_time:200122ms step_avg:1010.72ms
step:209/5100 train_loss:4.4811 train_time:201099ms step_avg:1010.55ms
step:210/5100 train_loss:4.6438 train_time:202059ms step_avg:1010.30ms
step:211/5100 train_loss:4.5683 train_time:203050ms step_avg:1010.20ms
step:212/5100 train_loss:4.4473 train_time:204064ms step_avg:1010.22ms
step:213/5100 train_loss:4.5671 train_time:205046ms step_avg:1010.08ms
step:214/5100 train_loss:4.4178 train_time:206034ms step_avg:1009.97ms
step:215/5100 train_loss:4.4863 train_time:207014ms step_avg:1009.82ms
step:216/5100 train_loss:4.3499 train_time:208001ms step_avg:1009.71ms
step:217/5100 train_loss:4.4433 train_time:209015ms step_avg:1009.73ms
step:218/5100 train_loss:4.4116 train_time:210006ms step_avg:1009.64ms
step:219/5100 train_loss:4.4430 train_time:210999ms step_avg:1009.56ms
step:220/5100 train_loss:4.4377 train_time:212000ms step_avg:1009.52ms
step:221/5100 train_loss:4.4702 train_time:213023ms step_avg:1009.59ms
step:222/5100 train_loss:4.4860 train_time:213999ms step_avg:1009.43ms
step:223/5100 train_loss:4.4089 train_time:215001ms step_avg:1009.39ms
step:224/5100 train_loss:4.4086 train_time:216028ms step_avg:1009.48ms
step:225/5100 train_loss:4.6259 train_time:217025ms step_avg:1009.42ms
step:226/5100 train_loss:4.2373 train_time:218002ms step_avg:1009.27ms
step:227/5100 train_loss:4.3373 train_time:219026ms step_avg:1009.34ms
step:228/5100 train_loss:4.3356 train_time:219994ms step_avg:1009.14ms
step:229/5100 train_loss:4.4916 train_time:220982ms step_avg:1009.05ms
step:230/5100 train_loss:4.2764 train_time:221982ms step_avg:1009.01ms
step:231/5100 train_loss:4.4241 train_time:223019ms step_avg:1009.14ms
step:232/5100 train_loss:4.2795 train_time:224021ms step_avg:1009.10ms
step:233/5100 train_loss:4.3006 train_time:225051ms step_avg:1009.20ms
step:234/5100 train_loss:4.4603 train_time:226044ms step_avg:1009.12ms
step:235/5100 train_loss:4.3494 train_time:227032ms step_avg:1009.03ms
step:236/5100 train_loss:4.2423 train_time:228049ms step_avg:1009.07ms
step:237/5100 train_loss:4.4474 train_time:229065ms step_avg:1009.10ms
step:238/5100 train_loss:4.4117 train_time:230067ms step_avg:1009.07ms
step:239/5100 train_loss:4.2792 train_time:231075ms step_avg:1009.06ms
step:240/5100 train_loss:4.4267 train_time:232104ms step_avg:1009.15ms
step:241/5100 train_loss:4.4329 train_time:233103ms step_avg:1009.10ms
step:242/5100 train_loss:4.3132 train_time:234099ms step_avg:1009.05ms
step:243/5100 train_loss:4.4954 train_time:235123ms step_avg:1009.11ms
step:244/5100 train_loss:4.3322 train_time:236140ms step_avg:1009.14ms
step:245/5100 train_loss:4.3768 train_time:237155ms step_avg:1009.17ms
step:246/5100 train_loss:4.4450 train_time:238183ms step_avg:1009.25ms
step:247/5100 train_loss:4.3832 train_time:239178ms step_avg:1009.19ms
step:248/5100 train_loss:4.3215 train_time:240181ms step_avg:1009.17ms
step:249/5100 train_loss:4.4440 train_time:241183ms step_avg:1009.13ms
step:250/5100 train_loss:4.2209 train_time:242184ms step_avg:1009.10ms
step:250/5100 val_loss:4.3202 train_time:242187ms step_avg:1009.11ms
step:251/5100 train_loss:4.2695 train_time:243190ms step_avg:1009.09ms
step:252/5100 train_loss:4.3826 train_time:244181ms step_avg:1009.01ms
step:253/5100 train_loss:4.4251 train_time:245184ms step_avg:1008.99ms
step:254/5100 train_loss:4.2446 train_time:246224ms step_avg:1009.12ms
step:255/5100 train_loss:4.1964 train_time:247234ms step_avg:1009.12ms
step:256/5100 train_loss:4.3708 train_time:248241ms step_avg:1009.11ms
step:257/5100 train_loss:4.2869 train_time:249300ms step_avg:1009.31ms
step:258/5100 train_loss:4.2967 train_time:250287ms step_avg:1009.22ms
step:259/5100 train_loss:4.2644 train_time:251290ms step_avg:1009.20ms
step:260/5100 train_loss:4.3051 train_time:252297ms step_avg:1009.19ms
step:261/5100 train_loss:4.3446 train_time:253260ms step_avg:1009.00ms
step:262/5100 train_loss:4.3028 train_time:254266ms step_avg:1008.99ms
step:263/5100 train_loss:4.2780 train_time:255258ms step_avg:1008.92ms
step:264/5100 train_loss:4.1933 train_time:256278ms step_avg:1008.97ms
step:265/5100 train_loss:4.2782 train_time:257259ms step_avg:1008.86ms
step:266/5100 train_loss:4.1427 train_time:258241ms step_avg:1008.75ms
step:267/5100 train_loss:4.1939 train_time:259238ms step_avg:1008.71ms
step:268/5100 train_loss:4.2089 train_time:260228ms step_avg:1008.64ms
step:269/5100 train_loss:4.2224 train_time:261223ms step_avg:1008.58ms
step:270/5100 train_loss:4.1371 train_time:262215ms step_avg:1008.52ms
step:271/5100 train_loss:4.3736 train_time:263163ms step_avg:1008.29ms
step:272/5100 train_loss:4.2752 train_time:264186ms step_avg:1008.34ms
step:273/5100 train_loss:4.1794 train_time:265208ms step_avg:1008.40ms
step:274/5100 train_loss:4.2314 train_time:266202ms step_avg:1008.34ms
step:275/5100 train_loss:4.3093 train_time:267174ms step_avg:1008.20ms
step:276/5100 train_loss:4.3300 train_time:268180ms step_avg:1008.20ms
step:277/5100 train_loss:4.5014 train_time:269172ms step_avg:1008.14ms
step:278/5100 train_loss:4.2965 train_time:270173ms step_avg:1008.11ms
step:279/5100 train_loss:4.3659 train_time:271163ms step_avg:1008.04ms
step:280/5100 train_loss:4.2646 train_time:272173ms step_avg:1008.05ms
step:281/5100 train_loss:4.3942 train_time:273177ms step_avg:1008.03ms
step:282/5100 train_loss:4.2141 train_time:274164ms step_avg:1007.96ms
step:283/5100 train_loss:4.2374 train_time:275197ms step_avg:1008.05ms
step:284/5100 train_loss:4.1671 train_time:276197ms step_avg:1008.02ms
step:285/5100 train_loss:4.3158 train_time:277185ms step_avg:1007.95ms
step:286/5100 train_loss:4.3207 train_time:278190ms step_avg:1007.94ms
step:287/5100 train_loss:4.3470 train_time:279187ms step_avg:1007.89ms
step:288/5100 train_loss:4.1795 train_time:280172ms step_avg:1007.81ms
step:289/5100 train_loss:4.2770 train_time:281178ms step_avg:1007.81ms
step:290/5100 train_loss:4.1369 train_time:282167ms step_avg:1007.74ms
step:291/5100 train_loss:4.1304 train_time:283161ms step_avg:1007.69ms
step:292/5100 train_loss:4.2107 train_time:284199ms step_avg:1007.80ms
step:293/5100 train_loss:4.1265 train_time:285196ms step_avg:1007.76ms
step:294/5100 train_loss:4.1644 train_time:286206ms step_avg:1007.77ms
step:295/5100 train_loss:4.2109 train_time:287220ms step_avg:1007.79ms
step:296/5100 train_loss:4.0854 train_time:288230ms step_avg:1007.80ms
step:297/5100 train_loss:4.1160 train_time:289224ms step_avg:1007.75ms
step:298/5100 train_loss:4.1143 train_time:290216ms step_avg:1007.69ms
step:299/5100 train_loss:4.2262 train_time:291227ms step_avg:1007.71ms
step:300/5100 train_loss:4.0838 train_time:292235ms step_avg:1007.71ms
step:301/5100 train_loss:4.2221 train_time:293219ms step_avg:1007.62ms
step:302/5100 train_loss:4.2268 train_time:294206ms step_avg:1007.55ms
step:303/5100 train_loss:4.1722 train_time:295186ms step_avg:1007.46ms
step:304/5100 train_loss:4.2266 train_time:296206ms step_avg:1007.50ms
step:305/5100 train_loss:4.2108 train_time:297201ms step_avg:1007.46ms
step:306/5100 train_loss:4.6927 train_time:298212ms step_avg:1007.47ms
step:307/5100 train_loss:4.1778 train_time:299223ms step_avg:1007.48ms
step:308/5100 train_loss:4.0905 train_time:300205ms step_avg:1007.40ms
step:309/5100 train_loss:4.2477 train_time:301204ms step_avg:1007.37ms
step:310/5100 train_loss:4.0953 train_time:302208ms step_avg:1007.36ms
step:311/5100 train_loss:4.3260 train_time:303213ms step_avg:1007.35ms
step:312/5100 train_loss:4.1850 train_time:304225ms step_avg:1007.37ms
step:313/5100 train_loss:4.1062 train_time:305241ms step_avg:1007.40ms
step:314/5100 train_loss:4.2211 train_time:306271ms step_avg:1007.47ms
step:315/5100 train_loss:4.3326 train_time:307289ms step_avg:1007.50ms
step:316/5100 train_loss:4.1934 train_time:308317ms step_avg:1007.57ms
step:317/5100 train_loss:4.0264 train_time:309285ms step_avg:1007.44ms
step:318/5100 train_loss:4.1178 train_time:310303ms step_avg:1007.48ms
step:319/5100 train_loss:4.1522 train_time:311320ms step_avg:1007.51ms
step:320/5100 train_loss:4.1189 train_time:312334ms step_avg:1007.53ms
step:321/5100 train_loss:4.2365 train_time:313324ms step_avg:1007.47ms
step:322/5100 train_loss:4.1891 train_time:314327ms step_avg:1007.46ms
step:323/5100 train_loss:4.1589 train_time:315319ms step_avg:1007.41ms
step:324/5100 train_loss:4.2429 train_time:316330ms step_avg:1007.42ms
step:325/5100 train_loss:4.1988 train_time:317325ms step_avg:1007.38ms
step:326/5100 train_loss:4.2684 train_time:318327ms step_avg:1007.36ms
step:327/5100 train_loss:4.1289 train_time:319327ms step_avg:1007.34ms
step:328/5100 train_loss:4.6237 train_time:320295ms step_avg:1007.22ms
step:329/5100 train_loss:4.3022 train_time:321281ms step_avg:1007.15ms
step:330/5100 train_loss:4.0465 train_time:322271ms step_avg:1007.10ms
step:331/5100 train_loss:4.0040 train_time:323243ms step_avg:1006.99ms
step:332/5100 train_loss:4.2090 train_time:324259ms step_avg:1007.02ms
step:333/5100 train_loss:4.1272 train_time:325313ms step_avg:1007.16ms
step:334/5100 train_loss:4.1120 train_time:326301ms step_avg:1007.10ms
step:335/5100 train_loss:4.0697 train_time:327317ms step_avg:1007.13ms
step:336/5100 train_loss:4.2456 train_time:328351ms step_avg:1007.21ms
step:337/5100 train_loss:4.1825 train_time:329387ms step_avg:1007.30ms
step:338/5100 train_loss:4.6487 train_time:330394ms step_avg:1007.30ms
step:339/5100 train_loss:4.1659 train_time:331381ms step_avg:1007.24ms
step:340/5100 train_loss:4.1142 train_time:332400ms step_avg:1007.27ms
step:341/5100 train_loss:4.1488 train_time:333389ms step_avg:1007.22ms
step:342/5100 train_loss:4.0664 train_time:334362ms step_avg:1007.11ms
step:343/5100 train_loss:4.0372 train_time:335383ms step_avg:1007.15ms
step:344/5100 train_loss:4.0887 train_time:336402ms step_avg:1007.19ms
step:345/5100 train_loss:4.2183 train_time:337385ms step_avg:1007.12ms
step:346/5100 train_loss:4.0577 train_time:338393ms step_avg:1007.12ms
step:347/5100 train_loss:3.9966 train_time:339414ms step_avg:1007.16ms
step:348/5100 train_loss:4.0376 train_time:340442ms step_avg:1007.23ms
step:349/5100 train_loss:4.0834 train_time:341430ms step_avg:1007.17ms
step:350/5100 train_loss:4.0447 train_time:342439ms step_avg:1007.17ms
step:351/5100 train_loss:3.7662 train_time:343428ms step_avg:1007.12ms
step:352/5100 train_loss:4.0390 train_time:344441ms step_avg:1007.14ms
step:353/5100 train_loss:4.3827 train_time:345448ms step_avg:1007.14ms
step:354/5100 train_loss:3.8805 train_time:346453ms step_avg:1007.13ms
step:355/5100 train_loss:4.1509 train_time:347452ms step_avg:1007.11ms
step:356/5100 train_loss:4.0134 train_time:348459ms step_avg:1007.11ms
step:357/5100 train_loss:4.1101 train_time:349472ms step_avg:1007.12ms
step:358/5100 train_loss:4.0519 train_time:350476ms step_avg:1007.12ms
step:359/5100 train_loss:4.0672 train_time:351487ms step_avg:1007.13ms
step:360/5100 train_loss:4.1356 train_time:352498ms step_avg:1007.14ms
step:361/5100 train_loss:3.6838 train_time:353486ms step_avg:1007.08ms
step:362/5100 train_loss:4.2377 train_time:354465ms step_avg:1007.00ms
step:363/5100 train_loss:4.1363 train_time:355470ms step_avg:1007.00ms
step:364/5100 train_loss:4.0607 train_time:356467ms step_avg:1006.97ms
step:365/5100 train_loss:3.9724 train_time:357458ms step_avg:1006.92ms
step:366/5100 train_loss:4.1395 train_time:358451ms step_avg:1006.89ms
step:367/5100 train_loss:4.0915 train_time:359460ms step_avg:1006.89ms
step:368/5100 train_loss:4.0743 train_time:360470ms step_avg:1006.90ms
step:369/5100 train_loss:4.0584 train_time:361455ms step_avg:1006.84ms
step:370/5100 train_loss:3.9563 train_time:362444ms step_avg:1006.79ms
step:371/5100 train_loss:4.1075 train_time:363454ms step_avg:1006.80ms
step:372/5100 train_loss:3.9762 train_time:364455ms step_avg:1006.78ms
step:373/5100 train_loss:3.9047 train_time:365434ms step_avg:1006.71ms
step:374/5100 train_loss:4.1274 train_time:366431ms step_avg:1006.68ms
step:375/5100 train_loss:4.0516 train_time:367418ms step_avg:1006.62ms
step:375/5100 val_loss:4.0475 train_time:367421ms step_avg:1006.63ms
step:376/5100 train_loss:4.0157 train_time:368441ms step_avg:1006.67ms
step:377/5100 train_loss:4.0898 train_time:369418ms step_avg:1006.59ms
step:378/5100 train_loss:4.0037 train_time:370604ms step_avg:1007.08ms
step:379/5100 train_loss:4.0605 train_time:371624ms step_avg:1007.11ms
step:380/5100 train_loss:4.0974 train_time:372886ms step_avg:1007.80ms
step:381/5100 train_loss:4.1595 train_time:373877ms step_avg:1007.75ms
step:382/5100 train_loss:4.0668 train_time:374865ms step_avg:1007.70ms
step:383/5100 train_loss:4.0375 train_time:375864ms step_avg:1007.68ms
step:384/5100 train_loss:4.0021 train_time:376832ms step_avg:1007.57ms
step:385/5100 train_loss:4.0851 train_time:377850ms step_avg:1007.60ms
step:386/5100 train_loss:3.9981 train_time:378853ms step_avg:1007.59ms
step:387/5100 train_loss:4.1093 train_time:379835ms step_avg:1007.52ms
step:388/5100 train_loss:4.2995 train_time:380841ms step_avg:1007.52ms
step:389/5100 train_loss:4.0164 train_time:381856ms step_avg:1007.53ms
step:390/5100 train_loss:4.0051 train_time:382856ms step_avg:1007.52ms
step:391/5100 train_loss:4.1048 train_time:383860ms step_avg:1007.51ms
step:392/5100 train_loss:4.0235 train_time:384852ms step_avg:1007.47ms
step:393/5100 train_loss:4.1312 train_time:385879ms step_avg:1007.52ms
step:394/5100 train_loss:3.9681 train_time:386872ms step_avg:1007.48ms
step:395/5100 train_loss:4.1060 train_time:387903ms step_avg:1007.54ms
step:396/5100 train_loss:3.8458 train_time:388910ms step_avg:1007.54ms
step:397/5100 train_loss:4.0517 train_time:389903ms step_avg:1007.50ms
step:398/5100 train_loss:4.1015 train_time:390877ms step_avg:1007.41ms
step:399/5100 train_loss:4.1236 train_time:391877ms step_avg:1007.39ms
step:400/5100 train_loss:3.9985 train_time:392867ms step_avg:1007.35ms
step:401/5100 train_loss:4.0564 train_time:393865ms step_avg:1007.33ms
step:402/5100 train_loss:4.1260 train_time:394850ms step_avg:1007.27ms
step:403/5100 train_loss:4.0553 train_time:395829ms step_avg:1007.20ms
step:404/5100 train_loss:4.1636 train_time:396849ms step_avg:1007.23ms
step:405/5100 train_loss:3.9105 train_time:397854ms step_avg:1007.23ms
step:406/5100 train_loss:4.0039 train_time:398846ms step_avg:1007.19ms
step:407/5100 train_loss:4.3008 train_time:399861ms step_avg:1007.21ms
step:408/5100 train_loss:4.0119 train_time:400845ms step_avg:1007.15ms
step:409/5100 train_loss:4.0246 train_time:401856ms step_avg:1007.16ms
step:410/5100 train_loss:4.0795 train_time:402846ms step_avg:1007.12ms
step:411/5100 train_loss:3.9575 train_time:403847ms step_avg:1007.10ms
step:412/5100 train_loss:3.9794 train_time:404831ms step_avg:1007.04ms
step:413/5100 train_loss:4.4038 train_time:405879ms step_avg:1007.14ms
step:414/5100 train_loss:3.8445 train_time:406868ms step_avg:1007.10ms
step:415/5100 train_loss:4.2265 train_time:407877ms step_avg:1007.10ms
step:416/5100 train_loss:3.9702 train_time:408856ms step_avg:1007.03ms
step:417/5100 train_loss:3.9808 train_time:409837ms step_avg:1006.97ms
step:418/5100 train_loss:4.1706 train_time:410833ms step_avg:1006.94ms
step:419/5100 train_loss:3.8949 train_time:411797ms step_avg:1006.84ms
step:420/5100 train_loss:4.0114 train_time:412801ms step_avg:1006.83ms
step:421/5100 train_loss:3.9385 train_time:413810ms step_avg:1006.84ms
step:422/5100 train_loss:3.8586 train_time:414837ms step_avg:1006.89ms
step:423/5100 train_loss:3.9899 train_time:415855ms step_avg:1006.91ms
step:424/5100 train_loss:4.0816 train_time:416820ms step_avg:1006.81ms
step:425/5100 train_loss:3.8421 train_time:417800ms step_avg:1006.75ms
step:426/5100 train_loss:4.0213 train_time:418776ms step_avg:1006.67ms
step:427/5100 train_loss:3.9037 train_time:419771ms step_avg:1006.65ms
step:428/5100 train_loss:4.1188 train_time:420782ms step_avg:1006.66ms
step:429/5100 train_loss:4.0326 train_time:421802ms step_avg:1006.69ms
step:430/5100 train_loss:3.9653 train_time:422813ms step_avg:1006.70ms
step:431/5100 train_loss:3.9347 train_time:423823ms step_avg:1006.71ms
step:432/5100 train_loss:3.8359 train_time:424818ms step_avg:1006.68ms
step:433/5100 train_loss:3.9733 train_time:425812ms step_avg:1006.65ms
step:434/5100 train_loss:4.0433 train_time:426780ms step_avg:1006.56ms
step:435/5100 train_loss:3.9759 train_time:427787ms step_avg:1006.56ms
step:436/5100 train_loss:4.0238 train_time:428782ms step_avg:1006.53ms
step:437/5100 train_loss:4.0370 train_time:429760ms step_avg:1006.46ms
step:438/5100 train_loss:3.9161 train_time:430779ms step_avg:1006.49ms
step:439/5100 train_loss:3.9307 train_time:431766ms step_avg:1006.45ms
step:440/5100 train_loss:3.9089 train_time:432755ms step_avg:1006.41ms
step:441/5100 train_loss:4.0921 train_time:433747ms step_avg:1006.37ms
step:442/5100 train_loss:3.9754 train_time:434734ms step_avg:1006.33ms
step:443/5100 train_loss:3.9572 train_time:435726ms step_avg:1006.29ms
step:444/5100 train_loss:3.8533 train_time:436714ms step_avg:1006.25ms
step:445/5100 train_loss:4.1170 train_time:437689ms step_avg:1006.18ms
step:446/5100 train_loss:4.0494 train_time:438687ms step_avg:1006.16ms
step:447/5100 train_loss:4.0415 train_time:439705ms step_avg:1006.19ms
step:448/5100 train_loss:3.9614 train_time:440704ms step_avg:1006.17ms
step:449/5100 train_loss:4.0530 train_time:441707ms step_avg:1006.17ms
step:450/5100 train_loss:3.8809 train_time:442688ms step_avg:1006.11ms
step:451/5100 train_loss:3.9289 train_time:443695ms step_avg:1006.11ms
step:452/5100 train_loss:3.7855 train_time:444698ms step_avg:1006.10ms
step:453/5100 train_loss:3.9112 train_time:445705ms step_avg:1006.11ms
step:454/5100 train_loss:3.8903 train_time:446680ms step_avg:1006.04ms
step:455/5100 train_loss:3.8466 train_time:447685ms step_avg:1006.03ms
step:456/5100 train_loss:4.0564 train_time:448690ms step_avg:1006.03ms
step:457/5100 train_loss:3.9275 train_time:449681ms step_avg:1006.00ms
step:458/5100 train_loss:3.9965 train_time:450660ms step_avg:1005.94ms
step:459/5100 train_loss:4.0440 train_time:451673ms step_avg:1005.95ms
step:460/5100 train_loss:3.8418 train_time:452666ms step_avg:1005.92ms
step:461/5100 train_loss:4.0132 train_time:453682ms step_avg:1005.95ms
step:462/5100 train_loss:3.9061 train_time:454675ms step_avg:1005.92ms
step:463/5100 train_loss:3.9323 train_time:455690ms step_avg:1005.94ms
step:464/5100 train_loss:3.9846 train_time:456700ms step_avg:1005.95ms
step:465/5100 train_loss:3.9233 train_time:457674ms step_avg:1005.88ms
step:466/5100 train_loss:3.9293 train_time:458648ms step_avg:1005.81ms
step:467/5100 train_loss:4.0248 train_time:459691ms step_avg:1005.89ms
step:468/5100 train_loss:4.0352 train_time:460712ms step_avg:1005.92ms
step:469/5100 train_loss:4.0083 train_time:461718ms step_avg:1005.92ms
step:470/5100 train_loss:3.8987 train_time:462769ms step_avg:1006.02ms
step:471/5100 train_loss:3.9822 train_time:463773ms step_avg:1006.01ms
step:472/5100 train_loss:4.0363 train_time:464784ms step_avg:1006.03ms
step:473/5100 train_loss:3.9752 train_time:465748ms step_avg:1005.94ms
step:474/5100 train_loss:3.9295 train_time:466752ms step_avg:1005.93ms
step:475/5100 train_loss:3.7860 train_time:467720ms step_avg:1005.85ms
step:476/5100 train_loss:4.2371 train_time:468731ms step_avg:1005.86ms
step:477/5100 train_loss:3.9754 train_time:469741ms step_avg:1005.87ms
step:478/5100 train_loss:3.7891 train_time:470743ms step_avg:1005.86ms
step:479/5100 train_loss:4.0232 train_time:471730ms step_avg:1005.82ms
step:480/5100 train_loss:3.9798 train_time:472722ms step_avg:1005.79ms
step:481/5100 train_loss:4.1219 train_time:473720ms step_avg:1005.78ms
step:482/5100 train_loss:3.9359 train_time:474748ms step_avg:1005.82ms
step:483/5100 train_loss:3.7330 train_time:475738ms step_avg:1005.79ms
step:484/5100 train_loss:4.0218 train_time:476747ms step_avg:1005.80ms
step:485/5100 train_loss:3.8693 train_time:477757ms step_avg:1005.80ms
step:486/5100 train_loss:3.8751 train_time:478762ms step_avg:1005.80ms
step:487/5100 train_loss:3.8075 train_time:479789ms step_avg:1005.85ms
step:488/5100 train_loss:3.8774 train_time:480766ms step_avg:1005.79ms
step:489/5100 train_loss:4.0790 train_time:481755ms step_avg:1005.75ms
step:490/5100 train_loss:3.9195 train_time:482771ms step_avg:1005.77ms
step:491/5100 train_loss:3.8098 train_time:483768ms step_avg:1005.75ms
step:492/5100 train_loss:3.8213 train_time:484790ms step_avg:1005.79ms
step:493/5100 train_loss:3.9402 train_time:485781ms step_avg:1005.76ms
step:494/5100 train_loss:3.7936 train_time:486757ms step_avg:1005.70ms
step:495/5100 train_loss:3.9248 train_time:487727ms step_avg:1005.62ms
step:496/5100 train_loss:3.8546 train_time:488742ms step_avg:1005.64ms
step:497/5100 train_loss:3.7478 train_time:489712ms step_avg:1005.57ms
step:498/5100 train_loss:3.9387 train_time:490734ms step_avg:1005.60ms
step:499/5100 train_loss:4.0105 train_time:491764ms step_avg:1005.65ms
step:500/5100 train_loss:4.0416 train_time:492736ms step_avg:1005.58ms
step:500/5100 val_loss:3.9156 train_time:492738ms step_avg:1005.59ms
step:501/5100 train_loss:3.9509 train_time:493738ms step_avg:1005.58ms
step:502/5100 train_loss:4.0055 train_time:494741ms step_avg:1005.57ms
step:503/5100 train_loss:3.9487 train_time:495767ms step_avg:1005.61ms
step:504/5100 train_loss:3.9852 train_time:496773ms step_avg:1005.61ms
step:505/5100 train_loss:3.9382 train_time:497759ms step_avg:1005.57ms
step:506/5100 train_loss:4.0269 train_time:498756ms step_avg:1005.56ms
step:507/5100 train_loss:3.8410 train_time:499752ms step_avg:1005.54ms
step:508/5100 train_loss:3.9705 train_time:500732ms step_avg:1005.49ms
step:509/5100 train_loss:4.0475 train_time:501740ms step_avg:1005.49ms
step:510/5100 train_loss:3.9833 train_time:502744ms step_avg:1005.49ms
step:511/5100 train_loss:3.7896 train_time:503762ms step_avg:1005.51ms
step:512/5100 train_loss:3.9839 train_time:504762ms step_avg:1005.50ms
step:513/5100 train_loss:3.9339 train_time:505767ms step_avg:1005.50ms
step:514/5100 train_loss:3.8853 train_time:506786ms step_avg:1005.53ms
step:515/5100 train_loss:3.9733 train_time:507781ms step_avg:1005.51ms
step:516/5100 train_loss:3.9493 train_time:508776ms step_avg:1005.49ms
step:517/5100 train_loss:4.2876 train_time:509742ms step_avg:1005.41ms
step:518/5100 train_loss:3.8873 train_time:510720ms step_avg:1005.35ms
step:519/5100 train_loss:3.9904 train_time:511732ms step_avg:1005.37ms
step:520/5100 train_loss:3.8910 train_time:512748ms step_avg:1005.39ms
step:521/5100 train_loss:3.8914 train_time:513769ms step_avg:1005.42ms
step:522/5100 train_loss:3.8454 train_time:514771ms step_avg:1005.41ms
step:523/5100 train_loss:3.8622 train_time:515758ms step_avg:1005.38ms
step:524/5100 train_loss:4.4890 train_time:516766ms step_avg:1005.38ms
step:525/5100 train_loss:3.9526 train_time:517765ms step_avg:1005.37ms
step:526/5100 train_loss:3.8923 train_time:518757ms step_avg:1005.34ms
step:527/5100 train_loss:3.9017 train_time:519758ms step_avg:1005.33ms
step:528/5100 train_loss:3.8516 train_time:520751ms step_avg:1005.31ms
step:529/5100 train_loss:3.8363 train_time:521761ms step_avg:1005.32ms
step:530/5100 train_loss:4.0587 train_time:522768ms step_avg:1005.32ms
step:531/5100 train_loss:3.8496 train_time:523768ms step_avg:1005.31ms
step:532/5100 train_loss:4.1252 train_time:524780ms step_avg:1005.33ms
step:533/5100 train_loss:3.9420 train_time:525797ms step_avg:1005.35ms
step:534/5100 train_loss:3.8620 train_time:526790ms step_avg:1005.32ms
step:535/5100 train_loss:3.8838 train_time:527786ms step_avg:1005.31ms
step:536/5100 train_loss:3.8158 train_time:528807ms step_avg:1005.34ms
step:537/5100 train_loss:3.9498 train_time:529797ms step_avg:1005.31ms
step:538/5100 train_loss:3.9427 train_time:530806ms step_avg:1005.32ms
step:539/5100 train_loss:3.8358 train_time:531846ms step_avg:1005.38ms
step:540/5100 train_loss:4.3275 train_time:532868ms step_avg:1005.41ms
step:541/5100 train_loss:3.8678 train_time:533889ms step_avg:1005.44ms
step:542/5100 train_loss:3.9877 train_time:534898ms step_avg:1005.45ms
step:543/5100 train_loss:3.8128 train_time:535946ms step_avg:1005.53ms
step:544/5100 train_loss:3.7942 train_time:536931ms step_avg:1005.49ms
step:545/5100 train_loss:3.8723 train_time:537936ms step_avg:1005.49ms
step:546/5100 train_loss:3.7967 train_time:538928ms step_avg:1005.46ms
step:547/5100 train_loss:3.8425 train_time:539914ms step_avg:1005.43ms
step:548/5100 train_loss:3.8588 train_time:540900ms step_avg:1005.39ms
step:549/5100 train_loss:3.8317 train_time:541899ms step_avg:1005.38ms
step:550/5100 train_loss:3.9317 train_time:542889ms step_avg:1005.35ms
step:551/5100 train_loss:3.8128 train_time:543870ms step_avg:1005.30ms
step:552/5100 train_loss:3.8294 train_time:544877ms step_avg:1005.31ms
step:553/5100 train_loss:4.1611 train_time:545922ms step_avg:1005.38ms
step:554/5100 train_loss:3.9587 train_time:546926ms step_avg:1005.38ms
step:555/5100 train_loss:3.9170 train_time:547939ms step_avg:1005.39ms
step:556/5100 train_loss:3.8600 train_time:548951ms step_avg:1005.40ms
step:557/5100 train_loss:3.8987 train_time:549962ms step_avg:1005.42ms
step:558/5100 train_loss:3.5557 train_time:550941ms step_avg:1005.37ms
step:559/5100 train_loss:3.8142 train_time:551925ms step_avg:1005.33ms
step:560/5100 train_loss:3.8549 train_time:552890ms step_avg:1005.25ms
step:561/5100 train_loss:3.8962 train_time:553920ms step_avg:1005.30ms
step:562/5100 train_loss:3.8092 train_time:554913ms step_avg:1005.28ms
step:563/5100 train_loss:3.7513 train_time:555924ms step_avg:1005.29ms
step:564/5100 train_loss:3.9648 train_time:556967ms step_avg:1005.36ms
step:565/5100 train_loss:3.7721 train_time:557958ms step_avg:1005.33ms
step:566/5100 train_loss:3.8884 train_time:558969ms step_avg:1005.34ms
step:567/5100 train_loss:3.8337 train_time:560245ms step_avg:1005.83ms
step:568/5100 train_loss:3.7927 train_time:561335ms step_avg:1005.98ms
step:569/5100 train_loss:3.8892 train_time:562327ms step_avg:1005.95ms
step:570/5100 train_loss:3.8651 train_time:563609ms step_avg:1006.45ms
step:571/5100 train_loss:3.8884 train_time:564604ms step_avg:1006.42ms
step:572/5100 train_loss:3.9677 train_time:565584ms step_avg:1006.38ms
step:573/5100 train_loss:3.9232 train_time:566593ms step_avg:1006.38ms
step:574/5100 train_loss:3.9269 train_time:567589ms step_avg:1006.36ms
step:575/5100 train_loss:3.9807 train_time:568566ms step_avg:1006.31ms
step:576/5100 train_loss:3.9367 train_time:569564ms step_avg:1006.30ms
step:577/5100 train_loss:3.9518 train_time:570569ms step_avg:1006.29ms
step:578/5100 train_loss:3.8838 train_time:571588ms step_avg:1006.32ms
step:579/5100 train_loss:3.8727 train_time:572561ms step_avg:1006.26ms
step:580/5100 train_loss:3.8602 train_time:573543ms step_avg:1006.21ms
step:581/5100 train_loss:3.8067 train_time:574546ms step_avg:1006.21ms
step:582/5100 train_loss:3.8297 train_time:575524ms step_avg:1006.16ms
step:583/5100 train_loss:4.0599 train_time:576517ms step_avg:1006.14ms
step:584/5100 train_loss:3.8337 train_time:577521ms step_avg:1006.13ms
step:585/5100 train_loss:3.7874 train_time:578496ms step_avg:1006.08ms
step:586/5100 train_loss:3.9844 train_time:579503ms step_avg:1006.08ms
step:587/5100 train_loss:3.7292 train_time:580517ms step_avg:1006.10ms
step:588/5100 train_loss:3.8669 train_time:581499ms step_avg:1006.05ms
step:589/5100 train_loss:3.8527 train_time:582508ms step_avg:1006.06ms
step:590/5100 train_loss:4.2124 train_time:583488ms step_avg:1006.01ms
step:591/5100 train_loss:3.9844 train_time:584454ms step_avg:1005.94ms
step:592/5100 train_loss:3.7207 train_time:585443ms step_avg:1005.92ms
step:593/5100 train_loss:3.7444 train_time:586429ms step_avg:1005.88ms
step:594/5100 train_loss:3.7276 train_time:587429ms step_avg:1005.87ms
step:595/5100 train_loss:3.7653 train_time:588428ms step_avg:1005.86ms
step:596/5100 train_loss:4.1305 train_time:589441ms step_avg:1005.87ms
step:597/5100 train_loss:3.8434 train_time:590454ms step_avg:1005.88ms
step:598/5100 train_loss:3.7808 train_time:591462ms step_avg:1005.89ms
step:599/5100 train_loss:3.8602 train_time:592457ms step_avg:1005.87ms
step:600/5100 train_loss:3.6786 train_time:593465ms step_avg:1005.87ms
step:601/5100 train_loss:3.8013 train_time:594475ms step_avg:1005.88ms
step:602/5100 train_loss:3.8342 train_time:595471ms step_avg:1005.86ms
step:603/5100 train_loss:3.8606 train_time:596503ms step_avg:1005.91ms
step:604/5100 train_loss:3.9793 train_time:597520ms step_avg:1005.93ms
step:605/5100 train_loss:3.8309 train_time:598497ms step_avg:1005.88ms
step:606/5100 train_loss:3.8181 train_time:599506ms step_avg:1005.88ms
step:607/5100 train_loss:3.7672 train_time:600498ms step_avg:1005.86ms
step:608/5100 train_loss:4.0220 train_time:601481ms step_avg:1005.82ms
step:609/5100 train_loss:3.8524 train_time:602462ms step_avg:1005.78ms
step:610/5100 train_loss:3.8205 train_time:603470ms step_avg:1005.78ms
step:611/5100 train_loss:3.9232 train_time:604516ms step_avg:1005.85ms
step:612/5100 train_loss:3.8196 train_time:605552ms step_avg:1005.90ms
step:613/5100 train_loss:3.7989 train_time:606550ms step_avg:1005.89ms
step:614/5100 train_loss:3.9631 train_time:607556ms step_avg:1005.89ms
step:615/5100 train_loss:3.9175 train_time:608534ms step_avg:1005.84ms
step:616/5100 train_loss:3.8899 train_time:609539ms step_avg:1005.84ms
step:617/5100 train_loss:3.8233 train_time:610497ms step_avg:1005.76ms
step:618/5100 train_loss:3.7715 train_time:611505ms step_avg:1005.76ms
step:619/5100 train_loss:3.8825 train_time:612512ms step_avg:1005.77ms
step:620/5100 train_loss:3.7827 train_time:613506ms step_avg:1005.75ms
step:621/5100 train_loss:3.7884 train_time:614478ms step_avg:1005.69ms
step:622/5100 train_loss:4.1043 train_time:615477ms step_avg:1005.68ms
step:623/5100 train_loss:3.7943 train_time:616474ms step_avg:1005.67ms
step:624/5100 train_loss:3.8234 train_time:617456ms step_avg:1005.63ms
step:625/5100 train_loss:3.9000 train_time:618435ms step_avg:1005.58ms
step:625/5100 val_loss:3.8287 train_time:618437ms step_avg:1005.59ms
step:626/5100 train_loss:3.9185 train_time:619432ms step_avg:1005.57ms
step:627/5100 train_loss:3.9487 train_time:620437ms step_avg:1005.57ms
step:628/5100 train_loss:3.9383 train_time:621421ms step_avg:1005.54ms
step:629/5100 train_loss:3.9717 train_time:622407ms step_avg:1005.50ms
step:630/5100 train_loss:3.7932 train_time:623411ms step_avg:1005.50ms
step:631/5100 train_loss:3.9177 train_time:624436ms step_avg:1005.53ms
step:632/5100 train_loss:3.9565 train_time:625437ms step_avg:1005.53ms
step:633/5100 train_loss:3.8600 train_time:626459ms step_avg:1005.55ms
step:634/5100 train_loss:3.7874 train_time:627468ms step_avg:1005.56ms
step:635/5100 train_loss:3.8863 train_time:628495ms step_avg:1005.59ms
step:636/5100 train_loss:4.1481 train_time:629484ms step_avg:1005.57ms
step:637/5100 train_loss:3.7349 train_time:630489ms step_avg:1005.57ms
step:638/5100 train_loss:3.5525 train_time:631489ms step_avg:1005.56ms
step:639/5100 train_loss:3.7805 train_time:632483ms step_avg:1005.54ms
step:640/5100 train_loss:3.8215 train_time:633515ms step_avg:1005.58ms
step:641/5100 train_loss:3.7753 train_time:634519ms step_avg:1005.58ms
step:642/5100 train_loss:3.7771 train_time:635509ms step_avg:1005.55ms
step:643/5100 train_loss:3.8238 train_time:636481ms step_avg:1005.50ms
step:644/5100 train_loss:3.8359 train_time:637474ms step_avg:1005.48ms
step:645/5100 train_loss:3.7622 train_time:638481ms step_avg:1005.48ms
step:646/5100 train_loss:3.9752 train_time:639478ms step_avg:1005.47ms
step:647/5100 train_loss:3.8809 train_time:640483ms step_avg:1005.47ms
step:648/5100 train_loss:3.8683 train_time:641474ms step_avg:1005.44ms
step:649/5100 train_loss:3.9022 train_time:642477ms step_avg:1005.44ms
step:650/5100 train_loss:3.9636 train_time:643478ms step_avg:1005.43ms
step:651/5100 train_loss:3.8224 train_time:644482ms step_avg:1005.43ms
step:652/5100 train_loss:3.9627 train_time:645458ms step_avg:1005.39ms
step:653/5100 train_loss:3.7855 train_time:646455ms step_avg:1005.37ms
step:654/5100 train_loss:3.8636 train_time:647464ms step_avg:1005.38ms
step:655/5100 train_loss:3.6280 train_time:648467ms step_avg:1005.38ms
step:656/5100 train_loss:3.7735 train_time:649450ms step_avg:1005.34ms
step:657/5100 train_loss:3.7814 train_time:650468ms step_avg:1005.36ms
step:658/5100 train_loss:3.7121 train_time:651464ms step_avg:1005.35ms
step:659/5100 train_loss:3.8911 train_time:652492ms step_avg:1005.38ms
step:660/5100 train_loss:3.7928 train_time:653490ms step_avg:1005.37ms
step:661/5100 train_loss:3.8815 train_time:654476ms step_avg:1005.34ms
step:662/5100 train_loss:3.9510 train_time:655448ms step_avg:1005.29ms
step:663/5100 train_loss:3.8634 train_time:656465ms step_avg:1005.31ms
step:664/5100 train_loss:3.7449 train_time:657472ms step_avg:1005.31ms
step:665/5100 train_loss:3.8371 train_time:658463ms step_avg:1005.29ms
step:666/5100 train_loss:3.7014 train_time:659469ms step_avg:1005.29ms
step:667/5100 train_loss:3.9871 train_time:660470ms step_avg:1005.28ms
step:668/5100 train_loss:3.8211 train_time:661468ms step_avg:1005.27ms
step:669/5100 train_loss:3.8296 train_time:662463ms step_avg:1005.25ms
step:670/5100 train_loss:3.6852 train_time:663468ms step_avg:1005.26ms
step:671/5100 train_loss:3.7961 train_time:664447ms step_avg:1005.21ms
step:672/5100 train_loss:3.7577 train_time:665451ms step_avg:1005.21ms
step:673/5100 train_loss:3.7778 train_time:666444ms step_avg:1005.19ms
step:674/5100 train_loss:4.0534 train_time:667433ms step_avg:1005.17ms
step:675/5100 train_loss:3.8433 train_time:668434ms step_avg:1005.16ms
step:676/5100 train_loss:3.9163 train_time:669444ms step_avg:1005.17ms
step:677/5100 train_loss:3.6889 train_time:670463ms step_avg:1005.19ms
step:678/5100 train_loss:3.8007 train_time:671442ms step_avg:1005.15ms
step:679/5100 train_loss:3.7425 train_time:672429ms step_avg:1005.13ms
step:680/5100 train_loss:3.8853 train_time:673430ms step_avg:1005.12ms
step:681/5100 train_loss:3.7849 train_time:674433ms step_avg:1005.12ms
step:682/5100 train_loss:3.8093 train_time:675408ms step_avg:1005.07ms
step:683/5100 train_loss:3.8855 train_time:676397ms step_avg:1005.05ms
step:684/5100 train_loss:3.9387 train_time:677386ms step_avg:1005.02ms
step:685/5100 train_loss:3.8344 train_time:678337ms step_avg:1004.94ms
step:686/5100 train_loss:3.9026 train_time:679311ms step_avg:1004.90ms
step:687/5100 train_loss:3.8364 train_time:680337ms step_avg:1004.93ms
step:688/5100 train_loss:3.8812 train_time:681337ms step_avg:1004.92ms
step:689/5100 train_loss:3.5140 train_time:682349ms step_avg:1004.93ms
step:690/5100 train_loss:3.6195 train_time:683342ms step_avg:1004.91ms
step:691/5100 train_loss:3.7568 train_time:684328ms step_avg:1004.89ms
step:692/5100 train_loss:3.6334 train_time:685344ms step_avg:1004.90ms
step:693/5100 train_loss:3.8454 train_time:686354ms step_avg:1004.91ms
step:694/5100 train_loss:3.8670 train_time:687363ms step_avg:1004.92ms
step:695/5100 train_loss:3.7474 train_time:688380ms step_avg:1004.93ms
step:696/5100 train_loss:3.7350 train_time:689422ms step_avg:1004.99ms
step:697/5100 train_loss:4.0553 train_time:690416ms step_avg:1004.97ms
step:698/5100 train_loss:3.7945 train_time:691427ms step_avg:1004.98ms
step:699/5100 train_loss:3.8413 train_time:692414ms step_avg:1004.95ms
step:700/5100 train_loss:4.0028 train_time:693394ms step_avg:1004.92ms
step:701/5100 train_loss:3.7720 train_time:694409ms step_avg:1004.93ms
step:702/5100 train_loss:3.7418 train_time:695409ms step_avg:1004.93ms
step:703/5100 train_loss:3.7247 train_time:696423ms step_avg:1004.94ms
step:704/5100 train_loss:3.6765 train_time:697436ms step_avg:1004.95ms
step:705/5100 train_loss:3.7645 train_time:698438ms step_avg:1004.95ms
step:706/5100 train_loss:3.7591 train_time:699432ms step_avg:1004.93ms
step:707/5100 train_loss:3.7727 train_time:700471ms step_avg:1004.98ms
step:708/5100 train_loss:3.8504 train_time:701493ms step_avg:1005.00ms
step:709/5100 train_loss:3.8003 train_time:702490ms step_avg:1004.99ms
step:710/5100 train_loss:3.7788 train_time:703508ms step_avg:1005.01ms
step:711/5100 train_loss:3.7459 train_time:704561ms step_avg:1005.08ms
step:712/5100 train_loss:3.7863 train_time:705572ms step_avg:1005.09ms
step:713/5100 train_loss:3.8493 train_time:706564ms step_avg:1005.07ms
step:714/5100 train_loss:3.8476 train_time:707570ms step_avg:1005.07ms
step:715/5100 train_loss:3.7709 train_time:708563ms step_avg:1005.05ms
step:716/5100 train_loss:3.7741 train_time:709582ms step_avg:1005.07ms
step:717/5100 train_loss:3.7863 train_time:710589ms step_avg:1005.08ms
step:718/5100 train_loss:3.9333 train_time:711605ms step_avg:1005.09ms
step:719/5100 train_loss:3.7977 train_time:712644ms step_avg:1005.14ms
step:720/5100 train_loss:3.8683 train_time:713635ms step_avg:1005.12ms
step:721/5100 train_loss:4.0322 train_time:714678ms step_avg:1005.17ms
step:722/5100 train_loss:3.6536 train_time:715693ms step_avg:1005.19ms
step:723/5100 train_loss:3.9244 train_time:716711ms step_avg:1005.20ms
step:724/5100 train_loss:3.9774 train_time:717717ms step_avg:1005.21ms
step:725/5100 train_loss:3.7645 train_time:718712ms step_avg:1005.19ms
step:726/5100 train_loss:3.8444 train_time:719698ms step_avg:1005.16ms
step:727/5100 train_loss:3.7449 train_time:720685ms step_avg:1005.14ms
step:728/5100 train_loss:3.7570 train_time:721678ms step_avg:1005.12ms
step:729/5100 train_loss:3.9428 train_time:722685ms step_avg:1005.13ms
step:730/5100 train_loss:3.8835 train_time:723673ms step_avg:1005.10ms
step:731/5100 train_loss:3.8764 train_time:724706ms step_avg:1005.14ms
step:732/5100 train_loss:3.7662 train_time:725694ms step_avg:1005.12ms
step:733/5100 train_loss:3.7899 train_time:726714ms step_avg:1005.14ms
step:734/5100 train_loss:4.0285 train_time:727737ms step_avg:1005.16ms
step:735/5100 train_loss:3.7601 train_time:728742ms step_avg:1005.16ms
step:736/5100 train_loss:3.8184 train_time:729741ms step_avg:1005.15ms
step:737/5100 train_loss:3.9431 train_time:730725ms step_avg:1005.12ms
step:738/5100 train_loss:3.8586 train_time:731712ms step_avg:1005.10ms
step:739/5100 train_loss:3.8007 train_time:732728ms step_avg:1005.11ms
step:740/5100 train_loss:3.6967 train_time:733737ms step_avg:1005.12ms
step:741/5100 train_loss:4.3419 train_time:734728ms step_avg:1005.10ms
step:742/5100 train_loss:3.6915 train_time:735703ms step_avg:1005.06ms
step:743/5100 train_loss:3.7789 train_time:736728ms step_avg:1005.09ms
step:744/5100 train_loss:3.7805 train_time:737745ms step_avg:1005.10ms
step:745/5100 train_loss:3.8425 train_time:738740ms step_avg:1005.09ms
step:746/5100 train_loss:3.8152 train_time:739752ms step_avg:1005.10ms
step:747/5100 train_loss:3.7979 train_time:740742ms step_avg:1005.08ms
step:748/5100 train_loss:3.8268 train_time:741707ms step_avg:1005.02ms
step:749/5100 train_loss:3.7665 train_time:742725ms step_avg:1005.04ms
step:750/5100 train_loss:3.7632 train_time:743737ms step_avg:1005.05ms
step:750/5100 val_loss:3.7717 train_time:743740ms step_avg:1005.05ms
step:751/5100 train_loss:3.8035 train_time:744735ms step_avg:1005.04ms
step:752/5100 train_loss:3.7661 train_time:745759ms step_avg:1005.07ms
step:753/5100 train_loss:3.7985 train_time:746785ms step_avg:1005.09ms
step:754/5100 train_loss:3.8243 train_time:747793ms step_avg:1005.10ms
step:755/5100 train_loss:3.7857 train_time:748784ms step_avg:1005.08ms
step:756/5100 train_loss:3.8639 train_time:750002ms step_avg:1005.36ms
step:757/5100 train_loss:3.6912 train_time:751020ms step_avg:1005.38ms
step:758/5100 train_loss:3.9324 train_time:751997ms step_avg:1005.34ms
step:759/5100 train_loss:3.8477 train_time:753002ms step_avg:1005.34ms
step:760/5100 train_loss:3.7774 train_time:754269ms step_avg:1005.69ms
step:761/5100 train_loss:3.8925 train_time:755267ms step_avg:1005.68ms
step:762/5100 train_loss:3.5997 train_time:756298ms step_avg:1005.72ms
step:763/5100 train_loss:3.7516 train_time:757284ms step_avg:1005.69ms
step:764/5100 train_loss:3.8636 train_time:758267ms step_avg:1005.66ms
step:765/5100 train_loss:3.5144 train_time:759278ms step_avg:1005.67ms
step:766/5100 train_loss:3.9444 train_time:760305ms step_avg:1005.69ms
step:767/5100 train_loss:3.7928 train_time:761310ms step_avg:1005.69ms
step:768/5100 train_loss:3.7603 train_time:762331ms step_avg:1005.71ms
step:769/5100 train_loss:3.7767 train_time:763327ms step_avg:1005.70ms
step:770/5100 train_loss:3.7908 train_time:764339ms step_avg:1005.71ms
step:771/5100 train_loss:3.8527 train_time:765346ms step_avg:1005.71ms
step:772/5100 train_loss:4.0835 train_time:766350ms step_avg:1005.71ms
step:773/5100 train_loss:3.6599 train_time:767380ms step_avg:1005.74ms
step:774/5100 train_loss:3.8551 train_time:768373ms step_avg:1005.72ms
step:775/5100 train_loss:3.8328 train_time:769436ms step_avg:1005.80ms
step:776/5100 train_loss:3.8062 train_time:770425ms step_avg:1005.78ms
step:777/5100 train_loss:3.5990 train_time:771459ms step_avg:1005.81ms
step:778/5100 train_loss:3.6089 train_time:772439ms step_avg:1005.78ms
step:779/5100 train_loss:3.6758 train_time:773440ms step_avg:1005.77ms
step:780/5100 train_loss:3.7640 train_time:774467ms step_avg:1005.80ms
step:781/5100 train_loss:3.7978 train_time:775451ms step_avg:1005.77ms
step:782/5100 train_loss:3.8571 train_time:776465ms step_avg:1005.78ms
step:783/5100 train_loss:3.7726 train_time:777473ms step_avg:1005.79ms
step:784/5100 train_loss:3.7698 train_time:778428ms step_avg:1005.72ms
step:785/5100 train_loss:3.7708 train_time:779430ms step_avg:1005.72ms
step:786/5100 train_loss:3.7521 train_time:780460ms step_avg:1005.75ms
step:787/5100 train_loss:3.6542 train_time:781455ms step_avg:1005.73ms
step:788/5100 train_loss:3.9104 train_time:782460ms step_avg:1005.73ms
step:789/5100 train_loss:3.6975 train_time:783463ms step_avg:1005.73ms
step:790/5100 train_loss:3.7609 train_time:784468ms step_avg:1005.73ms
step:791/5100 train_loss:3.8249 train_time:785461ms step_avg:1005.71ms
step:792/5100 train_loss:3.9539 train_time:786448ms step_avg:1005.69ms
step:793/5100 train_loss:3.9635 train_time:787417ms step_avg:1005.64ms
step:794/5100 train_loss:3.6769 train_time:788472ms step_avg:1005.70ms
step:795/5100 train_loss:3.7995 train_time:789458ms step_avg:1005.68ms
step:796/5100 train_loss:3.8535 train_time:790452ms step_avg:1005.66ms
step:797/5100 train_loss:3.9651 train_time:791462ms step_avg:1005.67ms
step:798/5100 train_loss:3.7142 train_time:792482ms step_avg:1005.69ms
step:799/5100 train_loss:3.8607 train_time:793451ms step_avg:1005.64ms
step:800/5100 train_loss:3.7511 train_time:794457ms step_avg:1005.64ms
step:801/5100 train_loss:3.7358 train_time:795433ms step_avg:1005.60ms
step:802/5100 train_loss:3.8293 train_time:796430ms step_avg:1005.59ms
step:803/5100 train_loss:3.6946 train_time:797448ms step_avg:1005.61ms
step:804/5100 train_loss:3.7272 train_time:798501ms step_avg:1005.67ms
step:805/5100 train_loss:3.8309 train_time:799514ms step_avg:1005.68ms
step:806/5100 train_loss:3.7257 train_time:800506ms step_avg:1005.66ms
step:807/5100 train_loss:3.7362 train_time:801512ms step_avg:1005.66ms
step:808/5100 train_loss:3.8441 train_time:802516ms step_avg:1005.66ms
step:809/5100 train_loss:3.7491 train_time:803543ms step_avg:1005.69ms
step:810/5100 train_loss:3.6802 train_time:804563ms step_avg:1005.70ms
step:811/5100 train_loss:3.7598 train_time:805577ms step_avg:1005.71ms
step:812/5100 train_loss:3.8030 train_time:806591ms step_avg:1005.72ms
step:813/5100 train_loss:3.7920 train_time:807598ms step_avg:1005.73ms
step:814/5100 train_loss:3.8231 train_time:808603ms step_avg:1005.72ms
step:815/5100 train_loss:3.7704 train_time:809616ms step_avg:1005.73ms
step:816/5100 train_loss:3.7586 train_time:810636ms step_avg:1005.75ms
step:817/5100 train_loss:3.8589 train_time:811641ms step_avg:1005.75ms
step:818/5100 train_loss:3.9609 train_time:812662ms step_avg:1005.77ms
step:819/5100 train_loss:3.7200 train_time:813661ms step_avg:1005.76ms
step:820/5100 train_loss:3.9231 train_time:814624ms step_avg:1005.71ms
step:821/5100 train_loss:3.7034 train_time:815640ms step_avg:1005.72ms
step:822/5100 train_loss:3.7396 train_time:816640ms step_avg:1005.71ms
step:823/5100 train_loss:3.8632 train_time:817622ms step_avg:1005.68ms
step:824/5100 train_loss:3.7843 train_time:818609ms step_avg:1005.66ms
step:825/5100 train_loss:3.7118 train_time:819614ms step_avg:1005.66ms
step:826/5100 train_loss:3.8084 train_time:820620ms step_avg:1005.66ms
step:827/5100 train_loss:3.6941 train_time:821636ms step_avg:1005.67ms
step:828/5100 train_loss:3.9331 train_time:822627ms step_avg:1005.66ms
step:829/5100 train_loss:3.8222 train_time:823643ms step_avg:1005.67ms
step:830/5100 train_loss:3.8774 train_time:824619ms step_avg:1005.63ms
step:831/5100 train_loss:3.7302 train_time:825598ms step_avg:1005.60ms
step:832/5100 train_loss:3.7798 train_time:826617ms step_avg:1005.62ms
step:833/5100 train_loss:3.7179 train_time:827619ms step_avg:1005.61ms
step:834/5100 train_loss:3.8343 train_time:828625ms step_avg:1005.61ms
step:835/5100 train_loss:3.6781 train_time:829637ms step_avg:1005.62ms
step:836/5100 train_loss:3.6597 train_time:830666ms step_avg:1005.65ms
step:837/5100 train_loss:3.9177 train_time:831663ms step_avg:1005.64ms
step:838/5100 train_loss:3.6141 train_time:832659ms step_avg:1005.63ms
step:839/5100 train_loss:3.7884 train_time:833686ms step_avg:1005.65ms
step:840/5100 train_loss:3.6218 train_time:834694ms step_avg:1005.66ms
step:841/5100 train_loss:3.6707 train_time:835715ms step_avg:1005.67ms
step:842/5100 train_loss:3.7546 train_time:836721ms step_avg:1005.67ms
step:843/5100 train_loss:3.7775 train_time:837731ms step_avg:1005.68ms
step:844/5100 train_loss:3.7770 train_time:838731ms step_avg:1005.67ms
step:845/5100 train_loss:3.6261 train_time:839721ms step_avg:1005.65ms
step:846/5100 train_loss:3.8613 train_time:840743ms step_avg:1005.67ms
step:847/5100 train_loss:3.7304 train_time:841749ms step_avg:1005.67ms
step:848/5100 train_loss:3.6917 train_time:842763ms step_avg:1005.68ms
step:849/5100 train_loss:3.8289 train_time:843761ms step_avg:1005.67ms
step:850/5100 train_loss:3.6955 train_time:844784ms step_avg:1005.70ms
step:851/5100 train_loss:3.6456 train_time:845802ms step_avg:1005.71ms
step:852/5100 train_loss:3.9412 train_time:846806ms step_avg:1005.71ms
step:853/5100 train_loss:3.6491 train_time:847792ms step_avg:1005.68ms
step:854/5100 train_loss:3.7603 train_time:848781ms step_avg:1005.66ms
step:855/5100 train_loss:3.8423 train_time:849784ms step_avg:1005.66ms
step:856/5100 train_loss:3.7301 train_time:850779ms step_avg:1005.65ms
step:857/5100 train_loss:3.7452 train_time:851797ms step_avg:1005.66ms
step:858/5100 train_loss:3.7963 train_time:852781ms step_avg:1005.64ms
step:859/5100 train_loss:3.6858 train_time:853796ms step_avg:1005.65ms
step:860/5100 train_loss:3.7605 train_time:854785ms step_avg:1005.63ms
step:861/5100 train_loss:3.7938 train_time:855778ms step_avg:1005.62ms
step:862/5100 train_loss:3.8387 train_time:856781ms step_avg:1005.61ms
step:863/5100 train_loss:3.7830 train_time:857762ms step_avg:1005.58ms
step:864/5100 train_loss:3.7702 train_time:858756ms step_avg:1005.57ms
step:865/5100 train_loss:3.6006 train_time:859777ms step_avg:1005.59ms
step:866/5100 train_loss:3.7857 train_time:860768ms step_avg:1005.57ms
step:867/5100 train_loss:4.0594 train_time:861786ms step_avg:1005.58ms
step:868/5100 train_loss:3.6434 train_time:862804ms step_avg:1005.60ms
step:869/5100 train_loss:3.8315 train_time:863803ms step_avg:1005.59ms
step:870/5100 train_loss:3.8095 train_time:864813ms step_avg:1005.60ms
step:871/5100 train_loss:3.6455 train_time:865818ms step_avg:1005.60ms
step:872/5100 train_loss:3.6330 train_time:866823ms step_avg:1005.60ms
step:873/5100 train_loss:3.8573 train_time:867826ms step_avg:1005.59ms
step:874/5100 train_loss:3.6502 train_time:868836ms step_avg:1005.60ms
step:875/5100 train_loss:3.3731 train_time:869851ms step_avg:1005.61ms
step:875/5100 val_loss:3.7243 train_time:869853ms step_avg:1005.61ms
step:876/5100 train_loss:3.8389 train_time:870873ms step_avg:1005.63ms
step:877/5100 train_loss:3.6464 train_time:871889ms step_avg:1005.64ms
step:878/5100 train_loss:3.8247 train_time:872880ms step_avg:1005.62ms
step:879/5100 train_loss:3.6765 train_time:873895ms step_avg:1005.63ms
step:880/5100 train_loss:3.8508 train_time:874865ms step_avg:1005.59ms
step:881/5100 train_loss:3.5177 train_time:875888ms step_avg:1005.61ms
step:882/5100 train_loss:3.6961 train_time:876890ms step_avg:1005.61ms
step:883/5100 train_loss:3.8876 train_time:877902ms step_avg:1005.61ms
step:884/5100 train_loss:4.0468 train_time:878879ms step_avg:1005.58ms
step:885/5100 train_loss:3.7751 train_time:879851ms step_avg:1005.54ms
step:886/5100 train_loss:3.6828 train_time:880841ms step_avg:1005.53ms
step:887/5100 train_loss:3.7806 train_time:881816ms step_avg:1005.49ms
step:888/5100 train_loss:4.2812 train_time:882815ms step_avg:1005.48ms
step:889/5100 train_loss:4.0330 train_time:883812ms step_avg:1005.47ms
step:890/5100 train_loss:3.7215 train_time:884823ms step_avg:1005.48ms
step:891/5100 train_loss:3.7357 train_time:885847ms step_avg:1005.50ms
step:892/5100 train_loss:3.5601 train_time:886848ms step_avg:1005.50ms
step:893/5100 train_loss:3.9010 train_time:887855ms step_avg:1005.50ms
step:894/5100 train_loss:3.6259 train_time:888835ms step_avg:1005.47ms
step:895/5100 train_loss:3.8666 train_time:889855ms step_avg:1005.49ms
step:896/5100 train_loss:3.8878 train_time:890875ms step_avg:1005.50ms
step:897/5100 train_loss:3.6955 train_time:891871ms step_avg:1005.49ms
step:898/5100 train_loss:3.7366 train_time:892850ms step_avg:1005.46ms
step:899/5100 train_loss:3.7880 train_time:893861ms step_avg:1005.47ms
step:900/5100 train_loss:3.6797 train_time:894865ms step_avg:1005.47ms
step:901/5100 train_loss:3.6172 train_time:895817ms step_avg:1005.41ms
step:902/5100 train_loss:3.8302 train_time:896839ms step_avg:1005.42ms
step:903/5100 train_loss:3.8354 train_time:897838ms step_avg:1005.42ms
step:904/5100 train_loss:3.7296 train_time:898850ms step_avg:1005.43ms
step:905/5100 train_loss:3.7004 train_time:899863ms step_avg:1005.43ms
step:906/5100 train_loss:3.6896 train_time:900888ms step_avg:1005.46ms
step:907/5100 train_loss:3.9203 train_time:901871ms step_avg:1005.43ms
step:908/5100 train_loss:3.7073 train_time:902863ms step_avg:1005.42ms
step:909/5100 train_loss:3.7515 train_time:903867ms step_avg:1005.41ms
step:910/5100 train_loss:3.6544 train_time:904855ms step_avg:1005.39ms
step:911/5100 train_loss:3.7437 train_time:905849ms step_avg:1005.38ms
step:912/5100 train_loss:3.8171 train_time:906817ms step_avg:1005.34ms
step:913/5100 train_loss:3.8025 train_time:907802ms step_avg:1005.32ms
step:914/5100 train_loss:3.6776 train_time:908812ms step_avg:1005.32ms
step:915/5100 train_loss:3.9299 train_time:909821ms step_avg:1005.33ms
step:916/5100 train_loss:3.7236 train_time:910834ms step_avg:1005.34ms
step:917/5100 train_loss:3.8211 train_time:911847ms step_avg:1005.34ms
step:918/5100 train_loss:3.7947 train_time:912862ms step_avg:1005.35ms
step:919/5100 train_loss:5.0164 train_time:913874ms step_avg:1005.36ms
step:920/5100 train_loss:3.7169 train_time:914879ms step_avg:1005.36ms
step:921/5100 train_loss:3.7692 train_time:915914ms step_avg:1005.39ms
step:922/5100 train_loss:3.7323 train_time:916932ms step_avg:1005.41ms
step:923/5100 train_loss:3.7909 train_time:917942ms step_avg:1005.41ms
step:924/5100 train_loss:3.8003 train_time:918957ms step_avg:1005.42ms
step:925/5100 train_loss:3.8837 train_time:919938ms step_avg:1005.40ms
step:926/5100 train_loss:3.8626 train_time:920947ms step_avg:1005.40ms
step:927/5100 train_loss:3.7513 train_time:921947ms step_avg:1005.39ms
step:928/5100 train_loss:3.7432 train_time:922949ms step_avg:1005.39ms
step:929/5100 train_loss:3.9662 train_time:923963ms step_avg:1005.40ms
step:930/5100 train_loss:3.8142 train_time:924995ms step_avg:1005.43ms
step:931/5100 train_loss:3.5968 train_time:926000ms step_avg:1005.43ms
step:932/5100 train_loss:3.6885 train_time:927035ms step_avg:1005.46ms
step:933/5100 train_loss:3.8723 train_time:928054ms step_avg:1005.48ms
step:934/5100 train_loss:3.6015 train_time:929061ms step_avg:1005.48ms
step:935/5100 train_loss:3.7716 train_time:930069ms step_avg:1005.48ms
step:936/5100 train_loss:3.6444 train_time:931085ms step_avg:1005.49ms
step:937/5100 train_loss:3.7024 train_time:932063ms step_avg:1005.46ms
step:938/5100 train_loss:3.8101 train_time:933041ms step_avg:1005.43ms
step:939/5100 train_loss:3.7397 train_time:934044ms step_avg:1005.43ms
step:940/5100 train_loss:3.8920 train_time:935034ms step_avg:1005.41ms
step:941/5100 train_loss:3.6784 train_time:936035ms step_avg:1005.41ms
step:942/5100 train_loss:3.7419 train_time:937065ms step_avg:1005.43ms
step:943/5100 train_loss:3.5457 train_time:938068ms step_avg:1005.43ms
step:944/5100 train_loss:3.8973 train_time:939126ms step_avg:1005.49ms
step:945/5100 train_loss:3.6018 train_time:940331ms step_avg:1005.70ms
step:946/5100 train_loss:3.6220 train_time:941351ms step_avg:1005.72ms
step:947/5100 train_loss:5.2277 train_time:942357ms step_avg:1005.72ms
step:948/5100 train_loss:3.7938 train_time:943366ms step_avg:1005.72ms
step:949/5100 train_loss:3.6920 train_time:944367ms step_avg:1005.72ms
step:950/5100 train_loss:3.5885 train_time:945566ms step_avg:1005.92ms
step:951/5100 train_loss:3.6486 train_time:946571ms step_avg:1005.92ms
step:952/5100 train_loss:3.6002 train_time:947568ms step_avg:1005.91ms
step:953/5100 train_loss:3.6700 train_time:948571ms step_avg:1005.91ms
step:954/5100 train_loss:3.7506 train_time:949572ms step_avg:1005.90ms
step:955/5100 train_loss:3.6309 train_time:950568ms step_avg:1005.89ms
step:956/5100 train_loss:3.6735 train_time:951562ms step_avg:1005.88ms
step:957/5100 train_loss:3.6371 train_time:952557ms step_avg:1005.87ms
step:958/5100 train_loss:3.6986 train_time:953553ms step_avg:1005.86ms
step:959/5100 train_loss:3.6871 train_time:954552ms step_avg:1005.85ms
step:960/5100 train_loss:3.7005 train_time:955521ms step_avg:1005.81ms
step:961/5100 train_loss:3.5929 train_time:956547ms step_avg:1005.83ms
step:962/5100 train_loss:3.8467 train_time:957508ms step_avg:1005.79ms
step:963/5100 train_loss:3.8007 train_time:958513ms step_avg:1005.78ms
step:964/5100 train_loss:3.8772 train_time:959528ms step_avg:1005.79ms
step:965/5100 train_loss:3.6450 train_time:960499ms step_avg:1005.76ms
step:966/5100 train_loss:3.6825 train_time:961486ms step_avg:1005.74ms
step:967/5100 train_loss:3.9044 train_time:962490ms step_avg:1005.74ms
step:968/5100 train_loss:3.7282 train_time:963482ms step_avg:1005.72ms
step:969/5100 train_loss:3.7196 train_time:964465ms step_avg:1005.70ms
step:970/5100 train_loss:3.7721 train_time:965472ms step_avg:1005.70ms
step:971/5100 train_loss:3.5843 train_time:966443ms step_avg:1005.66ms
step:972/5100 train_loss:3.7465 train_time:967485ms step_avg:1005.70ms
step:973/5100 train_loss:3.6866 train_time:968479ms step_avg:1005.69ms
step:974/5100 train_loss:3.7396 train_time:969485ms step_avg:1005.69ms
step:975/5100 train_loss:3.8146 train_time:970459ms step_avg:1005.66ms
step:976/5100 train_loss:3.6894 train_time:971457ms step_avg:1005.65ms
step:977/5100 train_loss:3.8839 train_time:972477ms step_avg:1005.66ms
step:978/5100 train_loss:3.7637 train_time:973472ms step_avg:1005.65ms
step:979/5100 train_loss:3.5985 train_time:974488ms step_avg:1005.66ms
step:980/5100 train_loss:3.8905 train_time:975512ms step_avg:1005.68ms
step:981/5100 train_loss:3.6215 train_time:976487ms step_avg:1005.65ms
step:982/5100 train_loss:3.7845 train_time:977507ms step_avg:1005.67ms
step:983/5100 train_loss:3.7606 train_time:978495ms step_avg:1005.65ms
step:984/5100 train_loss:3.7740 train_time:979492ms step_avg:1005.64ms
step:985/5100 train_loss:3.7071 train_time:980478ms step_avg:1005.62ms
step:986/5100 train_loss:3.7966 train_time:981467ms step_avg:1005.60ms
step:987/5100 train_loss:3.6111 train_time:982471ms step_avg:1005.60ms
step:988/5100 train_loss:3.6910 train_time:983462ms step_avg:1005.58ms
step:989/5100 train_loss:3.6954 train_time:984437ms step_avg:1005.55ms
step:990/5100 train_loss:3.6319 train_time:985468ms step_avg:1005.58ms
step:991/5100 train_loss:3.8464 train_time:986488ms step_avg:1005.59ms
step:992/5100 train_loss:3.6666 train_time:987482ms step_avg:1005.58ms
step:993/5100 train_loss:3.6342 train_time:988478ms step_avg:1005.57ms
step:994/5100 train_loss:3.7158 train_time:989486ms step_avg:1005.58ms
step:995/5100 train_loss:3.7988 train_time:990495ms step_avg:1005.58ms
step:996/5100 train_loss:3.7411 train_time:991506ms step_avg:1005.58ms
step:997/5100 train_loss:3.6477 train_time:992503ms step_avg:1005.58ms
step:998/5100 train_loss:4.0067 train_time:993511ms step_avg:1005.58ms
step:999/5100 train_loss:3.6652 train_time:994492ms step_avg:1005.55ms
step:1000/5100 train_loss:3.7880 train_time:995509ms step_avg:1005.57ms
step:1000/5100 val_loss:3.6821 train_time:995512ms step_avg:1005.57ms
step:1001/5100 train_loss:3.6535 train_time:996533ms step_avg:1005.58ms
step:1002/5100 train_loss:3.7047 train_time:997554ms step_avg:1005.60ms
step:1003/5100 train_loss:3.5925 train_time:998561ms step_avg:1005.60ms
step:1004/5100 train_loss:3.7755 train_time:999563ms step_avg:1005.60ms
step:1005/5100 train_loss:3.8244 train_time:1000600ms step_avg:1005.63ms
step:1006/5100 train_loss:3.5994 train_time:1001609ms step_avg:1005.63ms
step:1007/5100 train_loss:3.6740 train_time:1002612ms step_avg:1005.63ms
step:1008/5100 train_loss:3.6476 train_time:1003600ms step_avg:1005.61ms
step:1009/5100 train_loss:3.7690 train_time:1004605ms step_avg:1005.61ms
step:1010/5100 train_loss:3.8759 train_time:1005630ms step_avg:1005.63ms
step:1011/5100 train_loss:3.7627 train_time:1006639ms step_avg:1005.63ms
step:1012/5100 train_loss:3.7275 train_time:1007627ms step_avg:1005.62ms
step:1013/5100 train_loss:3.5904 train_time:1008617ms step_avg:1005.60ms
step:1014/5100 train_loss:3.7442 train_time:1009616ms step_avg:1005.59ms
step:1015/5100 train_loss:3.8417 train_time:1010638ms step_avg:1005.61ms
step:1016/5100 train_loss:3.5537 train_time:1011627ms step_avg:1005.59ms
step:1017/5100 train_loss:3.6461 train_time:1012601ms step_avg:1005.56ms
step:1018/5100 train_loss:3.6495 train_time:1013603ms step_avg:1005.56ms
step:1019/5100 train_loss:3.5887 train_time:1014618ms step_avg:1005.57ms
step:1020/5100 train_loss:3.7347 train_time:1015618ms step_avg:1005.56ms
step:1021/5100 train_loss:3.6458 train_time:1016614ms step_avg:1005.55ms
step:1022/5100 train_loss:3.5797 train_time:1017614ms step_avg:1005.55ms
step:1023/5100 train_loss:3.6919 train_time:1018635ms step_avg:1005.56ms
step:1024/5100 train_loss:3.7156 train_time:1019611ms step_avg:1005.53ms
step:1025/5100 train_loss:3.6894 train_time:1020602ms step_avg:1005.52ms
step:1026/5100 train_loss:3.7055 train_time:1021576ms step_avg:1005.49ms
step:1027/5100 train_loss:3.8651 train_time:1022571ms step_avg:1005.48ms
step:1028/5100 train_loss:3.5386 train_time:1023578ms step_avg:1005.48ms
step:1029/5100 train_loss:3.6040 train_time:1024557ms step_avg:1005.45ms
step:1030/5100 train_loss:3.5666 train_time:1025550ms step_avg:1005.44ms
step:1031/5100 train_loss:3.7318 train_time:1026563ms step_avg:1005.45ms
step:1032/5100 train_loss:3.7165 train_time:1027536ms step_avg:1005.42ms
step:1033/5100 train_loss:3.8994 train_time:1028529ms step_avg:1005.40ms
step:1034/5100 train_loss:3.7070 train_time:1029537ms step_avg:1005.41ms
step:1035/5100 train_loss:3.6333 train_time:1030500ms step_avg:1005.37ms
step:1036/5100 train_loss:3.6501 train_time:1031483ms step_avg:1005.34ms
step:1037/5100 train_loss:3.7047 train_time:1032469ms step_avg:1005.33ms
step:1038/5100 train_loss:4.0135 train_time:1033473ms step_avg:1005.32ms
step:1039/5100 train_loss:3.8358 train_time:1034477ms step_avg:1005.32ms
step:1040/5100 train_loss:3.7325 train_time:1035485ms step_avg:1005.32ms
step:1041/5100 train_loss:3.6298 train_time:1036477ms step_avg:1005.31ms
step:1042/5100 train_loss:3.6934 train_time:1037492ms step_avg:1005.32ms
step:1043/5100 train_loss:3.7392 train_time:1038497ms step_avg:1005.32ms
step:1044/5100 train_loss:3.6637 train_time:1039491ms step_avg:1005.31ms
step:1045/5100 train_loss:3.6719 train_time:1040491ms step_avg:1005.31ms
step:1046/5100 train_loss:3.7548 train_time:1041464ms step_avg:1005.27ms
step:1047/5100 train_loss:3.6563 train_time:1042476ms step_avg:1005.28ms
step:1048/5100 train_loss:3.8595 train_time:1043466ms step_avg:1005.27ms
step:1049/5100 train_loss:3.7187 train_time:1044465ms step_avg:1005.26ms
step:1050/5100 train_loss:3.6406 train_time:1045500ms step_avg:1005.29ms
step:1051/5100 train_loss:3.6034 train_time:1046518ms step_avg:1005.30ms
step:1052/5100 train_loss:3.7309 train_time:1047510ms step_avg:1005.29ms
step:1053/5100 train_loss:3.6030 train_time:1048514ms step_avg:1005.29ms
step:1054/5100 train_loss:3.9248 train_time:1049514ms step_avg:1005.28ms
step:1055/5100 train_loss:3.7592 train_time:1050500ms step_avg:1005.26ms
step:1056/5100 train_loss:3.6130 train_time:1051495ms step_avg:1005.25ms
step:1057/5100 train_loss:3.7211 train_time:1052510ms step_avg:1005.26ms
step:1058/5100 train_loss:3.7920 train_time:1053480ms step_avg:1005.23ms
step:1059/5100 train_loss:3.5260 train_time:1054506ms step_avg:1005.25ms
step:1060/5100 train_loss:3.6468 train_time:1055506ms step_avg:1005.24ms
step:1061/5100 train_loss:3.6706 train_time:1056523ms step_avg:1005.25ms
step:1062/5100 train_loss:3.6337 train_time:1057511ms step_avg:1005.24ms
step:1063/5100 train_loss:3.6084 train_time:1058513ms step_avg:1005.24ms
step:1064/5100 train_loss:3.7130 train_time:1059491ms step_avg:1005.21ms
step:1065/5100 train_loss:3.6102 train_time:1060458ms step_avg:1005.17ms
step:1066/5100 train_loss:3.5908 train_time:1061443ms step_avg:1005.15ms
step:1067/5100 train_loss:3.6183 train_time:1062440ms step_avg:1005.15ms
step:1068/5100 train_loss:3.5290 train_time:1063454ms step_avg:1005.16ms
step:1069/5100 train_loss:3.6480 train_time:1064465ms step_avg:1005.16ms
step:1070/5100 train_loss:3.5187 train_time:1065485ms step_avg:1005.17ms
step:1071/5100 train_loss:3.7701 train_time:1066511ms step_avg:1005.19ms
step:1072/5100 train_loss:3.7231 train_time:1067512ms step_avg:1005.19ms
step:1073/5100 train_loss:3.6738 train_time:1068532ms step_avg:1005.20ms
step:1074/5100 train_loss:3.7366 train_time:1069526ms step_avg:1005.19ms
step:1075/5100 train_loss:3.6806 train_time:1070517ms step_avg:1005.18ms
step:1076/5100 train_loss:3.6215 train_time:1071511ms step_avg:1005.17ms
step:1077/5100 train_loss:4.0136 train_time:1072494ms step_avg:1005.15ms
step:1078/5100 train_loss:3.6901 train_time:1073494ms step_avg:1005.14ms
step:1079/5100 train_loss:3.3659 train_time:1074487ms step_avg:1005.13ms
step:1080/5100 train_loss:3.7465 train_time:1075503ms step_avg:1005.14ms
step:1081/5100 train_loss:3.6784 train_time:1076491ms step_avg:1005.13ms
step:1082/5100 train_loss:3.7359 train_time:1077482ms step_avg:1005.11ms
step:1083/5100 train_loss:3.8342 train_time:1078488ms step_avg:1005.11ms
step:1084/5100 train_loss:3.7351 train_time:1079506ms step_avg:1005.13ms
step:1085/5100 train_loss:3.7051 train_time:1080499ms step_avg:1005.12ms
step:1086/5100 train_loss:3.6666 train_time:1081515ms step_avg:1005.13ms
step:1087/5100 train_loss:3.8656 train_time:1082531ms step_avg:1005.14ms
step:1088/5100 train_loss:3.7623 train_time:1083536ms step_avg:1005.14ms
step:1089/5100 train_loss:3.5856 train_time:1084530ms step_avg:1005.13ms
step:1090/5100 train_loss:3.6078 train_time:1085531ms step_avg:1005.12ms
step:1091/5100 train_loss:3.7254 train_time:1086523ms step_avg:1005.11ms
step:1092/5100 train_loss:3.5194 train_time:1087526ms step_avg:1005.11ms
step:1093/5100 train_loss:3.7211 train_time:1088533ms step_avg:1005.11ms
step:1094/5100 train_loss:3.8528 train_time:1089537ms step_avg:1005.11ms
