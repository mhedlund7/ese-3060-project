====================================================================================================
Experiment mode: lion
====================================================================================================

Hyperparameters (hyp):
  opt:
    train_epochs: 9.9
    batch_size: 1024
    lr: 11.5
    momentum: 0.85
    weight_decay: 0.0153
    bias_scaler: 64.0
    label_smoothing: 0.2
    whiten_bias_epochs: 3
  aug:
    flip: True
    translate: 2
  net:
    widths:
      block1: 64
      block2: 256
      block3: 256
    batchnorm_momentum: 0.6
    scaling_factor: 0.1111111111111111
    tta_level: 2

Accuracy statistics:
  Runs: 5
  Mean: 0.9238
  Std:  0.0015
  Min:  0.9209
  Max:  0.9253

Runtime statistics (seconds):
  Runs: 5
  Mean: 4.1672
  Std:  0.0051
  Min:  4.1581
  Max:  4.1729

Per-run results:
  Run    Accuracy    Time (s)
  ----   --------    --------
    0      0.9246      4.1581
    1      0.9209      4.1657
    2      0.9246      4.1688
    3      0.9253      4.1707
    4      0.9238      4.1729

====================================================================================================
TRAINING SCRIPT (code from log['code'])
====================================================================================================
# Modified airbench94.py for ESE 3060 Final Project
# Original Source: https://github.com/KellerJordan/cifar10-airbench/blob/master/legacy/airbench94.py

import os
import sys
import uuid
import argparse
from math import ceil

import torch
from torch import nn
import torch.nn.functional as F
import torchvision
import torchvision.transforms as T

torch.backends.cudnn.benchmark = True

#############################################
#              Lion Optimizer               #
#############################################

class Lion(torch.optim.Optimizer):
    def __init__(self, params, lr=1e-4, betas=(0.9, 0.99), weight_decay=0.0):
        if not 0.0 <= lr:
            raise ValueError('Invalid learning rate: {}'.format(lr))
        if not 0.0 <= betas[0] < 1.0:
            raise ValueError('Invalid beta parameter at index 0: {}'.format(betas[0]))
        if not 0.0 <= betas[1] < 1.0:
            raise ValueError('Invalid beta parameter at index 1: {}'.format(betas[1]))
        defaults = dict(lr=lr, betas=betas, weight_decay=weight_decay)
        super().__init__(params, defaults)

    @torch.no_grad()
    def step(self, closure=None):
        loss = None
        if closure is not None:
            with torch.enable_grad():
                loss = closure()

        for group in self.param_groups:
            for p in group['params']:
                if p.grad is None:
                    continue

                # Perform stepweight decay
                p.data.mul_(1 - group['lr'] * group['weight_decay'])

                grad = p.grad
                state = self.state[p]
                # State initialization
                if len(state) == 0:
                    state['exp_avg'] = torch.zeros_like(p)

                exp_avg = state['exp_avg']
                beta1, beta2 = group['betas']

                # Weight update
                update = exp_avg * beta1 + grad * (1 - beta1)
                p.add_(torch.sign(update), alpha=-group['lr'])

                # Decay the momentum running average
                exp_avg.mul_(beta2).add_(grad, alpha=1 - beta2)

        return loss

#############################################
#            Setup/Hyperparameters          #
#############################################

hyp = {
    'opt': {
        'train_epochs': 9.9,
        'batch_size': 1024,
        'lr': 11.5, 
        'momentum': 0.85,
        'weight_decay': 0.0153,
        'bias_scaler': 64.0,
        'label_smoothing': 0.2,
        'whiten_bias_epochs': 3,
    },
    'aug': {
        'flip': True,
        'translate': 2,
    },
    'net': {
        'widths': {
            'block1': 64,
            'block2': 256,
            'block3': 256,
        },
        'batchnorm_momentum': 0.6,
        'scaling_factor': 1/9,
        'tta_level': 2,
    },
}

#############################################
#                DataLoader                 #
#############################################

CIFAR_MEAN = torch.tensor((0.4914, 0.4822, 0.4465))
CIFAR_STD = torch.tensor((0.2470, 0.2435, 0.2616))

def batch_flip_lr(inputs):
    flip_mask = (torch.rand(len(inputs), device=inputs.device) < 0.5).view(-1, 1, 1, 1)
    return torch.where(flip_mask, inputs.flip(-1), inputs)

def batch_crop(images, crop_size):
    r = (images.size(-1) - crop_size)//2
    shifts = torch.randint(-r, r+1, size=(len(images), 2), device=images.device)
    images_out = torch.empty((len(images), 3, crop_size, crop_size), device=images.device, dtype=images.dtype)
    if r <= 2:
        for sy in range(-r, r+1):
            for sx in range(-r, r+1):
                mask = (shifts[:, 0] == sy) & (shifts[:, 1] == sx)
                images_out[mask] = images[mask, :, r+sy:r+sy+crop_size, r+sx:r+sx+crop_size]
    else:
        images_tmp = torch.empty((len(images), 3, crop_size, crop_size+2*r), device=images.device, dtype=images.dtype)
        for s in range(-r, r+1):
            mask = (shifts[:, 0] == s)
            images_tmp[mask] = images[mask, :, r+s:r+s+crop_size, :]
        for s in range(-r, r+1):
            mask = (shifts[:, 1] == s)
            images_out[mask] = images_tmp[mask, :, :, r+s:r+s+crop_size]
    return images_out

class CifarLoader:
    def __init__(self, path, train=True, batch_size=500, aug=None, drop_last=None, shuffle=None, gpu=0):
        data_path = os.path.join(path, 'train.pt' if train else 'test.pt')
        if not os.path.exists(data_path):
            dset = torchvision.datasets.CIFAR10(path, download=True, train=train)
            images = torch.tensor(dset.data)
            labels = torch.tensor(dset.targets)
            torch.save({'images': images, 'labels': labels, 'classes': dset.classes}, data_path)

        data = torch.load(data_path, map_location=torch.device(gpu))
        self.images, self.labels, self.classes = data['images'], data['labels'], data['classes']
        self.images = (self.images.half() / 255).permute(0, 3, 1, 2).to(memory_format=torch.channels_last)

        self.normalize = T.Normalize(CIFAR_MEAN, CIFAR_STD)
        self.proc_images = {}
        self.epoch = 0

        self.aug = aug or {}
        for k in self.aug.keys():
            assert k in ['flip', 'translate'], 'Unrecognized key: %s' % k

        self.batch_size = batch_size
        self.drop_last = train if drop_last is None else drop_last
        self.shuffle = train if shuffle is None else shuffle

    def __len__(self):
        return len(self.images)//self.batch_size if self.drop_last else ceil(len(self.images)/self.batch_size)

    def __iter__(self):
        if self.epoch == 0:
            images = self.proc_images['norm'] = self.normalize(self.images)
            if self.aug.get('flip', False):
                images = self.proc_images['flip'] = batch_flip_lr(images)
            pad = self.aug.get('translate', 0)
            if pad > 0:
                self.proc_images['pad'] = F.pad(images, (pad,)*4, 'reflect')

        if self.aug.get('translate', 0) > 0:
            images = batch_crop(self.proc_images['pad'], self.images.shape[-2])
        elif self.aug.get('flip', False):
            images = self.proc_images['flip']
        else:
            images = self.proc_images['norm']
        if self.aug.get('flip', False):
            if self.epoch % 2 == 1:
                images = images.flip(-1)

        self.epoch += 1
        indices = (torch.randperm if self.shuffle else torch.arange)(len(images), device=images.device)
        for i in range(len(self)):
            idxs = indices[i*self.batch_size:(i+1)*self.batch_size]
            yield (images[idxs], self.labels[idxs])

#############################################
#            Network Components             #
#############################################

class Flatten(nn.Module):
    def forward(self, x):
        return x.view(x.size(0), -1)

class Mul(nn.Module):
    def __init__(self, scale):
        super().__init__()
        self.scale = scale
    def forward(self, x):
        return x * self.scale

class BatchNorm(nn.BatchNorm2d):
    def __init__(self, num_features, momentum, eps=1e-12, weight=False, bias=True):
        super().__init__(num_features, eps=eps, momentum=1-momentum)
        self.weight.requires_grad = weight
        self.bias.requires_grad = bias

class Conv(nn.Conv2d):
    def __init__(self, in_channels, out_channels, kernel_size=3, padding='same', bias=False):
        super().__init__(in_channels, out_channels, kernel_size=kernel_size, padding=padding, bias=bias)

    def reset_parameters(self):
        super().reset_parameters()
        if self.bias is not None:
            self.bias.data.zero_()
        w = self.weight.data
        torch.nn.init.dirac_(w[:w.size(1)])

class ConvGroup(nn.Module):
    def __init__(self, channels_in, channels_out, batchnorm_momentum, act_fn=nn.GELU):
        super().__init__()
        self.conv1 = Conv(channels_in,  channels_out)
        self.pool = nn.MaxPool2d(2)
        self.norm1 = BatchNorm(channels_out, batchnorm_momentum)
        self.conv2 = Conv(channels_out, channels_out)
        self.norm2 = BatchNorm(channels_out, batchnorm_momentum)
        self.activ = act_fn()

    def forward(self, x):
        x = self.conv1(x)
        x = self.pool(x)
        x = self.norm1(x)
        x = self.activ(x)
        x = self.conv2(x)
        x = self.norm2(x)
        x = self.activ(x)
        return x

#############################################
#            Network Definition             #
#############################################

def make_net(act_fn=nn.GELU):
    widths = hyp['net']['widths']
    batchnorm_momentum = hyp['net']['batchnorm_momentum']
    whiten_kernel_size = 2
    whiten_width = 2 * 3 * whiten_kernel_size**2
    
    net = nn.Sequential(
        Conv(3, whiten_width, whiten_kernel_size, padding=0, bias=True),
        act_fn(),
        ConvGroup(whiten_width,     widths['block1'], batchnorm_momentum, act_fn=act_fn),
        ConvGroup(widths['block1'], widths['block2'], batchnorm_momentum, act_fn=act_fn),
        ConvGroup(widths['block2'], widths['block3'], batchnorm_momentum, act_fn=act_fn),
        nn.MaxPool2d(3),
        Flatten(),
        nn.Linear(widths['block3'], 10, bias=False),
        Mul(hyp['net']['scaling_factor']),
    )
    net[0].weight.requires_grad = False
    net = net.half().cuda()
    net = net.to(memory_format=torch.channels_last)
    for mod in net.modules():
        if isinstance(mod, BatchNorm):
            mod.float()
    return net

#############################################
#       Whitening Conv Initialization       #
#############################################

def get_patches(x, patch_shape):
    c, (h, w) = x.shape[1], patch_shape
    return x.unfold(2,h,1).unfold(3,w,1).transpose(1,3).reshape(-1,c,h,w).float()

def get_whitening_parameters(patches):
    n,c,h,w = patches.shape
    patches_flat = patches.view(n, -1)
    est_patch_covariance = (patches_flat.T @ patches_flat) / n
    eigenvalues, eigenvectors = torch.linalg.eigh(est_patch_covariance, UPLO='U')
    return eigenvalues.flip(0).view(-1, 1, 1, 1), eigenvectors.T.reshape(c*h*w,c,h,w).flip(0)

def init_whitening_conv(layer, train_set, eps=5e-4):
    patches = get_patches(train_set, patch_shape=layer.weight.data.shape[2:])
    eigenvalues, eigenvectors = get_whitening_parameters(patches)
    eigenvectors_scaled = eigenvectors / torch.sqrt(eigenvalues + eps)
    layer.weight.data[:] = torch.cat((eigenvectors_scaled, -eigenvectors_scaled))

############################################
#                Lookahead                 #
############################################

class LookaheadState:
    def __init__(self, net):
        self.net_ema = {k: v.clone() for k, v in net.state_dict().items()}

    def update(self, net, decay):
        for ema_param, net_param in zip(self.net_ema.values(), net.state_dict().values()):
            if net_param.dtype in (torch.half, torch.float):
                ema_param.lerp_(net_param, 1-decay)
                net_param.copy_(ema_param)

############################################
#                 Logging                  #
############################################

def print_columns(columns_list, is_head=False, is_final_entry=False):
    print_string = ''
    for col in columns_list:
        print_string += '|  %s  ' % col
    print_string += '|'
    if is_head:
        print('-'*len(print_string))
    print(print_string)
    if is_head or is_final_entry:
        print('-'*len(print_string))

logging_columns_list = ['run   ', 'epoch', 'train_loss', 'train_acc', 'val_acc', 'tta_val_acc', 'total_time_seconds', 'mode']
def print_training_details(variables, is_final_entry):
    formatted = []
    for col in logging_columns_list:
        var = variables.get(col.strip(), None)
        if type(var) in (int, str):
            res = str(var)
        elif type(var) is float:
            res = '{:0.4f}'.format(var)
        else:
            assert var is None
            res = ''
        formatted.append(res.rjust(len(col)))
    print_columns(formatted, is_final_entry=is_final_entry)

############################################
#               Evaluation                 #
############################################

def infer(model, loader, tta_level=0):
    def infer_basic(inputs, net):
        return net(inputs).clone()

    def infer_mirror(inputs, net):
        return 0.5 * net(inputs) + 0.5 * net(inputs.flip(-1))

    def infer_mirror_translate(inputs, net):
        logits = infer_mirror(inputs, net)
        pad = 1
        padded_inputs = F.pad(inputs, (pad,)*4, 'reflect')
        inputs_translate_list = [
            padded_inputs[:, :, 0:32, 0:32],
            padded_inputs[:, :, 2:34, 2:34],
        ]
        logits_translate_list = [infer_mirror(inputs_translate, net)
                                 for inputs_translate in inputs_translate_list]
        logits_translate = torch.stack(logits_translate_list).mean(0)
        return 0.5 * logits + 0.5 * logits_translate

    model.eval()
    test_images = loader.normalize(loader.images)
    infer_fn = [infer_basic, infer_mirror, infer_mirror_translate][tta_level]
    with torch.no_grad():
        return torch.cat([infer_fn(inputs, model) for inputs in test_images.split(2000)])

def evaluate(model, loader, tta_level=0):
    logits = infer(model, loader, tta_level)
    return (logits.argmax(1) == loader.labels).float().mean().item()

############################################
#                Training                  #
############################################

def main(run, args):
    mode = args.mode
    
    # Configure experiment settings based on mode
    use_lion = 'lion' in mode
    use_lookahead = 'lookahead' in mode or mode == 'baseline' or mode == 'hardswish'
    activation_fn = nn.Hardswish if 'hardswish' in mode else nn.GELU

    batch_size = hyp['opt']['batch_size']
    epochs = hyp['opt']['train_epochs']
    
    momentum = hyp['opt']['momentum']
    
    if use_lion:

        lr = (hyp['opt']['lr'] / 10.0) / 1024 # Heuristic downscaling
        wd = hyp['opt']['weight_decay'] * 1.0 
        lr_biases = lr * hyp['opt']['bias_scaler']
    else:
        # Original SGD Scaling Logic
        kilostep_scale = 1024 * (1 + 1 / (1 - momentum))
        lr = hyp['opt']['lr'] / kilostep_scale 
        wd = hyp['opt']['weight_decay'] * batch_size / kilostep_scale
        lr_biases = lr * hyp['opt']['bias_scaler']

    loss_fn = nn.CrossEntropyLoss(label_smoothing=hyp['opt']['label_smoothing'], reduction='none')
    test_loader = CifarLoader('cifar10', train=False, batch_size=2000)
    train_loader = CifarLoader('cifar10', train=True, batch_size=batch_size, aug=hyp['aug'])
    
    if run == 'warmup':
        # The only purpose of the first run is to warmup, so we can use dummy data
        train_loader.labels = torch.randint(0, 10, size=(len(train_loader.labels),), device=train_loader.labels.device)
    
    total_train_steps = ceil(len(train_loader) * epochs)

    # Initialize Model with selected activation
    model = make_net(act_fn=activation_fn)
    current_steps = 0

    norm_biases = [p for k, p in model.named_parameters() if 'norm' in k and p.requires_grad]
    other_params = [p for k, p in model.named_parameters() if 'norm' not in k and p.requires_grad]
    
    param_configs = [dict(params=norm_biases, lr=lr_biases, weight_decay=wd/lr_biases),
                     dict(params=other_params, lr=lr, weight_decay=wd/lr)]

    # Select Optimizer
    if use_lion:
        # Lion defaults: betas=(0.9, 0.99)
        optimizer = Lion(param_configs, betas=(0.9, 0.99))
    else:
        optimizer = torch.optim.SGD(param_configs, momentum=momentum, nesterov=True)

    def get_lr(step):
        warmup_steps = int(total_train_steps * 0.23)
        warmdown_steps = total_train_steps - warmup_steps
        if step < warmup_steps:
            frac = step / warmup_steps
            return 0.2 * (1 - frac) + 1.0 * frac
        else:
            frac = (step - warmup_steps) / warmdown_steps
            return 1.0 * (1 - frac) + 0.07 * frac
    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, get_lr)

    alpha_schedule = 0.95**5 * (torch.arange(total_train_steps+1) / total_train_steps)**3
    
    # Conditional Lookahead Initialization
    lookahead_state = LookaheadState(model) if use_lookahead else None

    starter = torch.cuda.Event(enable_timing=True)
    ender = torch.cuda.Event(enable_timing=True)
    total_time_seconds = 0.0

    # Initialize whitening
    starter.record()
    train_images = train_loader.normalize(train_loader.images[:5000])
    init_whitening_conv(model[0], train_images)
    ender.record()
    torch.cuda.synchronize()
    total_time_seconds += 1e-3 * starter.elapsed_time(ender)

    for epoch in range(ceil(epochs)):
        model[0].bias.requires_grad = (epoch < hyp['opt']['whiten_bias_epochs'])

        ####################
        #     Training     #
        ####################

        starter.record()
        model.train()
        for inputs, labels in train_loader:
            outputs = model(inputs)
            loss = loss_fn(outputs, labels).sum()
            optimizer.zero_grad(set_to_none=True)
            loss.backward()
            optimizer.step()
            scheduler.step()

            current_steps += 1

            # Conditional Lookahead Update
            if use_lookahead and current_steps % 5 == 0:
                lookahead_state.update(model, decay=alpha_schedule[current_steps].item())

            if current_steps >= total_train_steps:
                # Conditional Lookahead Final Sync
                if use_lookahead:
                    lookahead_state.update(model, decay=1.0)
                break

        ender.record()
        torch.cuda.synchronize()
        total_time_seconds += 1e-3 * starter.elapsed_time(ender)

        ####################
        #    Evaluation    #
        ####################

        train_acc = (outputs.detach().argmax(1) == labels).float().mean().item()
        train_loss = loss.item() / batch_size
        val_acc = evaluate(model, test_loader, tta_level=0)
        # Log mode along with stats
        print_training_details(locals(), is_final_entry=False)
        run = None 

    ####################
    #  TTA Evaluation  #
    ####################

    starter.record()
    tta_val_acc = evaluate(model, test_loader, tta_level=hyp['net']['tta_level'])
    ender.record()
    torch.cuda.synchronize()
    total_time_seconds += 1e-3 * starter.elapsed_time(ender)

    epoch = 'eval'
    print_training_details(locals(), is_final_entry=True)

    return tta_val_acc, total_time_seconds

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='CIFAR-10 Speedrun Experiments')
    parser.add_argument('--mode', type=str, default='baseline', 
                        choices=['baseline', 'lion', 'lion_lookahead', 'hardswish'],
                        help='Experiment mode: baseline, lion, lion_lookahead, or hardswish')
    parser.add_argument('--runs', type=int, default=5, help='Number of runs to perform')
    args = parser.parse_args()

    with open(sys.argv[0]) as f:
        code = f.read()

    print(f"Running Experiment Mode: {args.mode}")
    print_columns(logging_columns_list, is_head=True)
    
    # ------------------
    # Warmup Run Added
    # ------------------
    print("Performing warmup run...")
    # We pass 'warmup' as the run identifier. 
    # The return values are ignored.
    main('warmup', args)
    print("Warmup complete. Starting measured runs.")
    print('-' * 100) # Visual separator
    
    # Collect results
    results = []
    times = []
    for run in range(args.runs):
        acc, time = main(run, args)
        results.append(acc)
        times.append(time)
    
    accs = torch.tensor(results)
    times_t = torch.tensor(times)
    
    print(f'\nSummary for {args.mode}:')
    print('Accuracy - Mean: %.4f    Std: %.4f' % (accs.mean(), accs.std()))
    print('Time     - Mean: %.4f    Std: %.4f' % (times_t.mean(), times_t.std()))

    log = {
        'code': code, 
        'accs': accs, 
        'times': times_t,
        'mode': args.mode,
        'hyp': hyp
    }
    log_dir = os.path.join('logs', str(uuid.uuid4()))
    os.makedirs(log_dir, exist_ok=True)
    log_path = os.path.join(log_dir, 'log.pt')
    print(os.path.abspath(log_path))
    torch.save(log, log_path)

====================================================================================================
RAW LOG DICTIONARY DUMP
====================================================================================================

{ 'accs': tensor([0.9246, 0.9209, 0.9246, 0.9253, 0.9238]),
  'code': '# Modified airbench94.py for ESE 3060 Final Project\n'
          '# Original Source: '
          'https://github.com/KellerJordan/cifar10-airbench/blob/master/legacy/airbench94.py\n'
          '\n'
          'import os\n'
          'import sys\n'
          'import uuid\n'
          'import argparse\n'
          'from math import ceil\n'
          '\n'
          'import torch\n'
          'from torch import nn\n'
          'import torch.nn.functional as F\n'
          'import torchvision\n'
          'import torchvision.transforms as T\n'
          '\n'
          'torch.backends.cudnn.benchmark = True\n'
          '\n'
          '#############################################\n'
          '#              Lion Optimizer               #\n'
          '#############################################\n'
          '\n'
          'class Lion(torch.optim.Optimizer):\n'
          '    def __init__(self, params, lr=1e-4, betas=(0.9, 0.99), weight_decay=0.0):\n'
          '        if not 0.0 <= lr:\n'
          "            raise ValueError('Invalid learning rate: {}'.format(lr))\n"
          '        if not 0.0 <= betas[0] < 1.0:\n'
          "            raise ValueError('Invalid beta parameter at index 0: {}'.format(betas[0]))\n"
          '        if not 0.0 <= betas[1] < 1.0:\n'
          "            raise ValueError('Invalid beta parameter at index 1: {}'.format(betas[1]))\n"
          '        defaults = dict(lr=lr, betas=betas, weight_decay=weight_decay)\n'
          '        super().__init__(params, defaults)\n'
          '\n'
          '    @torch.no_grad()\n'
          '    def step(self, closure=None):\n'
          '        loss = None\n'
          '        if closure is not None:\n'
          '            with torch.enable_grad():\n'
          '                loss = closure()\n'
          '\n'
          '        for group in self.param_groups:\n'
          "            for p in group['params']:\n"
          '                if p.grad is None:\n'
          '                    continue\n'
          '\n'
          '                # Perform stepweight decay\n'
          "                p.data.mul_(1 - group['lr'] * group['weight_decay'])\n"
          '\n'
          '                grad = p.grad\n'
          '                state = self.state[p]\n'
          '                # State initialization\n'
          '                if len(state) == 0:\n'
          "                    state['exp_avg'] = torch.zeros_like(p)\n"
          '\n'
          "                exp_avg = state['exp_avg']\n"
          "                beta1, beta2 = group['betas']\n"
          '\n'
          '                # Weight update\n'
          '                update = exp_avg * beta1 + grad * (1 - beta1)\n'
          "                p.add_(torch.sign(update), alpha=-group['lr'])\n"
          '\n'
          '                # Decay the momentum running average\n'
          '                exp_avg.mul_(beta2).add_(grad, alpha=1 - beta2)\n'
          '\n'
          '        return loss\n'
          '\n'
          '#############################################\n'
          '#            Setup/Hyperparameters          #\n'
          '#############################################\n'
          '\n'
          'hyp = {\n'
          "    'opt': {\n"
          "        'train_epochs': 9.9,\n"
          "        'batch_size': 1024,\n"
          "        'lr': 11.5, \n"
          "        'momentum': 0.85,\n"
          "        'weight_decay': 0.0153,\n"
          "        'bias_scaler': 64.0,\n"
          "        'label_smoothing': 0.2,\n"
          "        'whiten_bias_epochs': 3,\n"
          '    },\n'
          "    'aug': {\n"
          "        'flip': True,\n"
          "        'translate': 2,\n"
          '    },\n'
          "    'net': {\n"
          "        'widths': {\n"
          "            'block1': 64,\n"
          "            'block2': 256,\n"
          "            'block3': 256,\n"
          '        },\n'
          "        'batchnorm_momentum': 0.6,\n"
          "        'scaling_factor': 1/9,\n"
          "        'tta_level': 2,\n"
          '    },\n'
          '}\n'
          '\n'
          '#############################################\n'
          '#                DataLoader                 #\n'
          '#############################################\n'
          '\n'
          'CIFAR_MEAN = torch.tensor((0.4914, 0.4822, 0.4465))\n'
          'CIFAR_STD = torch.tensor((0.2470, 0.2435, 0.2616))\n'
          '\n'
          'def batch_flip_lr(inputs):\n'
          '    flip_mask = (torch.rand(len(inputs), device=inputs.device) < 0.5).view(-1, 1, 1, '
          '1)\n'
          '    return torch.where(flip_mask, inputs.flip(-1), inputs)\n'
          '\n'
          'def batch_crop(images, crop_size):\n'
          '    r = (images.size(-1) - crop_size)//2\n'
          '    shifts = torch.randint(-r, r+1, size=(len(images), 2), device=images.device)\n'
          '    images_out = torch.empty((len(images), 3, crop_size, crop_size), '
          'device=images.device, dtype=images.dtype)\n'
          '    if r <= 2:\n'
          '        for sy in range(-r, r+1):\n'
          '            for sx in range(-r, r+1):\n'
          '                mask = (shifts[:, 0] == sy) & (shifts[:, 1] == sx)\n'
          '                images_out[mask] = images[mask, :, r+sy:r+sy+crop_size, '
          'r+sx:r+sx+crop_size]\n'
          '    else:\n'
          '        images_tmp = torch.empty((len(images), 3, crop_size, crop_size+2*r), '
          'device=images.device, dtype=images.dtype)\n'
          '        for s in range(-r, r+1):\n'
          '            mask = (shifts[:, 0] == s)\n'
          '            images_tmp[mask] = images[mask, :, r+s:r+s+crop_size, :]\n'
          '        for s in range(-r, r+1):\n'
          '            mask = (shifts[:, 1] == s)\n'
          '            images_out[mask] = images_tmp[mask, :, :, r+s:r+s+crop_size]\n'
          '    return images_out\n'
          '\n'
          'class CifarLoader:\n'
          '    def __init__(self, path, train=True, batch_size=500, aug=None, drop_last=None, '
          'shuffle=None, gpu=0):\n'
          "        data_path = os.path.join(path, 'train.pt' if train else 'test.pt')\n"
          '        if not os.path.exists(data_path):\n'
          '            dset = torchvision.datasets.CIFAR10(path, download=True, train=train)\n'
          '            images = torch.tensor(dset.data)\n'
          '            labels = torch.tensor(dset.targets)\n'
          "            torch.save({'images': images, 'labels': labels, 'classes': dset.classes}, "
          'data_path)\n'
          '\n'
          '        data = torch.load(data_path, map_location=torch.device(gpu))\n'
          "        self.images, self.labels, self.classes = data['images'], data['labels'], "
          "data['classes']\n"
          '        self.images = (self.images.half() / 255).permute(0, 3, 1, '
          '2).to(memory_format=torch.channels_last)\n'
          '\n'
          '        self.normalize = T.Normalize(CIFAR_MEAN, CIFAR_STD)\n'
          '        self.proc_images = {}\n'
          '        self.epoch = 0\n'
          '\n'
          '        self.aug = aug or {}\n'
          '        for k in self.aug.keys():\n'
          "            assert k in ['flip', 'translate'], 'Unrecognized key: %s' % k\n"
          '\n'
          '        self.batch_size = batch_size\n'
          '        self.drop_last = train if drop_last is None else drop_last\n'
          '        self.shuffle = train if shuffle is None else shuffle\n'
          '\n'
          '    def __len__(self):\n'
          '        return len(self.images)//self.batch_size if self.drop_last else '
          'ceil(len(self.images)/self.batch_size)\n'
          '\n'
          '    def __iter__(self):\n'
          '        if self.epoch == 0:\n'
          "            images = self.proc_images['norm'] = self.normalize(self.images)\n"
          "            if self.aug.get('flip', False):\n"
          "                images = self.proc_images['flip'] = batch_flip_lr(images)\n"
          "            pad = self.aug.get('translate', 0)\n"
          '            if pad > 0:\n'
          "                self.proc_images['pad'] = F.pad(images, (pad,)*4, 'reflect')\n"
          '\n'
          "        if self.aug.get('translate', 0) > 0:\n"
          "            images = batch_crop(self.proc_images['pad'], self.images.shape[-2])\n"
          "        elif self.aug.get('flip', False):\n"
          "            images = self.proc_images['flip']\n"
          '        else:\n'
          "            images = self.proc_images['norm']\n"
          "        if self.aug.get('flip', False):\n"
          '            if self.epoch % 2 == 1:\n'
          '                images = images.flip(-1)\n'
          '\n'
          '        self.epoch += 1\n'
          '        indices = (torch.randperm if self.shuffle else torch.arange)(len(images), '
          'device=images.device)\n'
          '        for i in range(len(self)):\n'
          '            idxs = indices[i*self.batch_size:(i+1)*self.batch_size]\n'
          '            yield (images[idxs], self.labels[idxs])\n'
          '\n'
          '#############################################\n'
          '#            Network Components             #\n'
          '#############################################\n'
          '\n'
          'class Flatten(nn.Module):\n'
          '    def forward(self, x):\n'
          '        return x.view(x.size(0), -1)\n'
          '\n'
          'class Mul(nn.Module):\n'
          '    def __init__(self, scale):\n'
          '        super().__init__()\n'
          '        self.scale = scale\n'
          '    def forward(self, x):\n'
          '        return x * self.scale\n'
          '\n'
          'class BatchNorm(nn.BatchNorm2d):\n'
          '    def __init__(self, num_features, momentum, eps=1e-12, weight=False, bias=True):\n'
          '        super().__init__(num_features, eps=eps, momentum=1-momentum)\n'
          '        self.weight.requires_grad = weight\n'
          '        self.bias.requires_grad = bias\n'
          '\n'
          'class Conv(nn.Conv2d):\n'
          "    def __init__(self, in_channels, out_channels, kernel_size=3, padding='same', "
          'bias=False):\n'
          '        super().__init__(in_channels, out_channels, kernel_size=kernel_size, '
          'padding=padding, bias=bias)\n'
          '\n'
          '    def reset_parameters(self):\n'
          '        super().reset_parameters()\n'
          '        if self.bias is not None:\n'
          '            self.bias.data.zero_()\n'
          '        w = self.weight.data\n'
          '        torch.nn.init.dirac_(w[:w.size(1)])\n'
          '\n'
          'class ConvGroup(nn.Module):\n'
          '    def __init__(self, channels_in, channels_out, batchnorm_momentum, act_fn=nn.GELU):\n'
          '        super().__init__()\n'
          '        self.conv1 = Conv(channels_in,  channels_out)\n'
          '        self.pool = nn.MaxPool2d(2)\n'
          '        self.norm1 = BatchNorm(channels_out, batchnorm_momentum)\n'
          '        self.conv2 = Conv(channels_out, channels_out)\n'
          '        self.norm2 = BatchNorm(channels_out, batchnorm_momentum)\n'
          '        self.activ = act_fn()\n'
          '\n'
          '    def forward(self, x):\n'
          '        x = self.conv1(x)\n'
          '        x = self.pool(x)\n'
          '        x = self.norm1(x)\n'
          '        x = self.activ(x)\n'
          '        x = self.conv2(x)\n'
          '        x = self.norm2(x)\n'
          '        x = self.activ(x)\n'
          '        return x\n'
          '\n'
          '#############################################\n'
          '#            Network Definition             #\n'
          '#############################################\n'
          '\n'
          'def make_net(act_fn=nn.GELU):\n'
          "    widths = hyp['net']['widths']\n"
          "    batchnorm_momentum = hyp['net']['batchnorm_momentum']\n"
          '    whiten_kernel_size = 2\n'
          '    whiten_width = 2 * 3 * whiten_kernel_size**2\n'
          '    \n'
          '    net = nn.Sequential(\n'
          '        Conv(3, whiten_width, whiten_kernel_size, padding=0, bias=True),\n'
          '        act_fn(),\n'
          "        ConvGroup(whiten_width,     widths['block1'], batchnorm_momentum, "
          'act_fn=act_fn),\n'
          "        ConvGroup(widths['block1'], widths['block2'], batchnorm_momentum, "
          'act_fn=act_fn),\n'
          "        ConvGroup(widths['block2'], widths['block3'], batchnorm_momentum, "
          'act_fn=act_fn),\n'
          '        nn.MaxPool2d(3),\n'
          '        Flatten(),\n'
          "        nn.Linear(widths['block3'], 10, bias=False),\n"
          "        Mul(hyp['net']['scaling_factor']),\n"
          '    )\n'
          '    net[0].weight.requires_grad = False\n'
          '    net = net.half().cuda()\n'
          '    net = net.to(memory_format=torch.channels_last)\n'
          '    for mod in net.modules():\n'
          '        if isinstance(mod, BatchNorm):\n'
          '            mod.float()\n'
          '    return net\n'
          '\n'
          '#############################################\n'
          '#       Whitening Conv Initialization       #\n'
          '#############################################\n'
          '\n'
          'def get_patches(x, patch_shape):\n'
          '    c, (h, w) = x.shape[1], patch_shape\n'
          '    return x.unfold(2,h,1).unfold(3,w,1).transpose(1,3).reshape(-1,c,h,w).float()\n'
          '\n'
          'def get_whitening_parameters(patches):\n'
          '    n,c,h,w = patches.shape\n'
          '    patches_flat = patches.view(n, -1)\n'
          '    est_patch_covariance = (patches_flat.T @ patches_flat) / n\n'
          "    eigenvalues, eigenvectors = torch.linalg.eigh(est_patch_covariance, UPLO='U')\n"
          '    return eigenvalues.flip(0).view(-1, 1, 1, 1), '
          'eigenvectors.T.reshape(c*h*w,c,h,w).flip(0)\n'
          '\n'
          'def init_whitening_conv(layer, train_set, eps=5e-4):\n'
          '    patches = get_patches(train_set, patch_shape=layer.weight.data.shape[2:])\n'
          '    eigenvalues, eigenvectors = get_whitening_parameters(patches)\n'
          '    eigenvectors_scaled = eigenvectors / torch.sqrt(eigenvalues + eps)\n'
          '    layer.weight.data[:] = torch.cat((eigenvectors_scaled, -eigenvectors_scaled))\n'
          '\n'
          '############################################\n'
          '#                Lookahead                 #\n'
          '############################################\n'
          '\n'
          'class LookaheadState:\n'
          '    def __init__(self, net):\n'
          '        self.net_ema = {k: v.clone() for k, v in net.state_dict().items()}\n'
          '\n'
          '    def update(self, net, decay):\n'
          '        for ema_param, net_param in zip(self.net_ema.values(), '
          'net.state_dict().values()):\n'
          '            if net_param.dtype in (torch.half, torch.float):\n'
          '                ema_param.lerp_(net_param, 1-decay)\n'
          '                net_param.copy_(ema_param)\n'
          '\n'
          '############################################\n'
          '#                 Logging                  #\n'
          '############################################\n'
          '\n'
          'def print_columns(columns_list, is_head=False, is_final_entry=False):\n'
          "    print_string = ''\n"
          '    for col in columns_list:\n'
          "        print_string += '|  %s  ' % col\n"
          "    print_string += '|'\n"
          '    if is_head:\n'
          "        print('-'*len(print_string))\n"
          '    print(print_string)\n'
          '    if is_head or is_final_entry:\n'
          "        print('-'*len(print_string))\n"
          '\n'
          "logging_columns_list = ['run   ', 'epoch', 'train_loss', 'train_acc', 'val_acc', "
          "'tta_val_acc', 'total_time_seconds', 'mode']\n"
          'def print_training_details(variables, is_final_entry):\n'
          '    formatted = []\n'
          '    for col in logging_columns_list:\n'
          '        var = variables.get(col.strip(), None)\n'
          '        if type(var) in (int, str):\n'
          '            res = str(var)\n'
          '        elif type(var) is float:\n'
          "            res = '{:0.4f}'.format(var)\n"
          '        else:\n'
          '            assert var is None\n'
          "            res = ''\n"
          '        formatted.append(res.rjust(len(col)))\n'
          '    print_columns(formatted, is_final_entry=is_final_entry)\n'
          '\n'
          '############################################\n'
          '#               Evaluation                 #\n'
          '############################################\n'
          '\n'
          'def infer(model, loader, tta_level=0):\n'
          '    def infer_basic(inputs, net):\n'
          '        return net(inputs).clone()\n'
          '\n'
          '    def infer_mirror(inputs, net):\n'
          '        return 0.5 * net(inputs) + 0.5 * net(inputs.flip(-1))\n'
          '\n'
          '    def infer_mirror_translate(inputs, net):\n'
          '        logits = infer_mirror(inputs, net)\n'
          '        pad = 1\n'
          "        padded_inputs = F.pad(inputs, (pad,)*4, 'reflect')\n"
          '        inputs_translate_list = [\n'
          '            padded_inputs[:, :, 0:32, 0:32],\n'
          '            padded_inputs[:, :, 2:34, 2:34],\n'
          '        ]\n'
          '        logits_translate_list = [infer_mirror(inputs_translate, net)\n'
          '                                 for inputs_translate in inputs_translate_list]\n'
          '        logits_translate = torch.stack(logits_translate_list).mean(0)\n'
          '        return 0.5 * logits + 0.5 * logits_translate\n'
          '\n'
          '    model.eval()\n'
          '    test_images = loader.normalize(loader.images)\n'
          '    infer_fn = [infer_basic, infer_mirror, infer_mirror_translate][tta_level]\n'
          '    with torch.no_grad():\n'
          '        return torch.cat([infer_fn(inputs, model) for inputs in '
          'test_images.split(2000)])\n'
          '\n'
          'def evaluate(model, loader, tta_level=0):\n'
          '    logits = infer(model, loader, tta_level)\n'
          '    return (logits.argmax(1) == loader.labels).float().mean().item()\n'
          '\n'
          '############################################\n'
          '#                Training                  #\n'
          '############################################\n'
          '\n'
          'def main(run, args):\n'
          '    mode = args.mode\n'
          '    \n'
          '    # Configure experiment settings based on mode\n'
          "    use_lion = 'lion' in mode\n"
          "    use_lookahead = 'lookahead' in mode or mode == 'baseline' or mode == 'hardswish'\n"
          "    activation_fn = nn.Hardswish if 'hardswish' in mode else nn.GELU\n"
          '\n'
          "    batch_size = hyp['opt']['batch_size']\n"
          "    epochs = hyp['opt']['train_epochs']\n"
          '    \n'
          "    momentum = hyp['opt']['momentum']\n"
          '    \n'
          '    if use_lion:\n'
          '\n'
          "        lr = (hyp['opt']['lr'] / 10.0) / 1024 # Heuristic downscaling\n"
          "        wd = hyp['opt']['weight_decay'] * 1.0 \n"
          "        lr_biases = lr * hyp['opt']['bias_scaler']\n"
          '    else:\n'
          '        # Original SGD Scaling Logic\n'
          '        kilostep_scale = 1024 * (1 + 1 / (1 - momentum))\n'
          "        lr = hyp['opt']['lr'] / kilostep_scale \n"
          "        wd = hyp['opt']['weight_decay'] * batch_size / kilostep_scale\n"
          "        lr_biases = lr * hyp['opt']['bias_scaler']\n"
          '\n'
          "    loss_fn = nn.CrossEntropyLoss(label_smoothing=hyp['opt']['label_smoothing'], "
          "reduction='none')\n"
          "    test_loader = CifarLoader('cifar10', train=False, batch_size=2000)\n"
          "    train_loader = CifarLoader('cifar10', train=True, batch_size=batch_size, "
          "aug=hyp['aug'])\n"
          '    \n'
          "    if run == 'warmup':\n"
          '        # The only purpose of the first run is to warmup, so we can use dummy data\n'
          '        train_loader.labels = torch.randint(0, 10, size=(len(train_loader.labels),), '
          'device=train_loader.labels.device)\n'
          '    \n'
          '    total_train_steps = ceil(len(train_loader) * epochs)\n'
          '\n'
          '    # Initialize Model with selected activation\n'
          '    model = make_net(act_fn=activation_fn)\n'
          '    current_steps = 0\n'
          '\n'
          "    norm_biases = [p for k, p in model.named_parameters() if 'norm' in k and "
          'p.requires_grad]\n'
          "    other_params = [p for k, p in model.named_parameters() if 'norm' not in k and "
          'p.requires_grad]\n'
          '    \n'
          '    param_configs = [dict(params=norm_biases, lr=lr_biases, '
          'weight_decay=wd/lr_biases),\n'
          '                     dict(params=other_params, lr=lr, weight_decay=wd/lr)]\n'
          '\n'
          '    # Select Optimizer\n'
          '    if use_lion:\n'
          '        # Lion defaults: betas=(0.9, 0.99)\n'
          '        optimizer = Lion(param_configs, betas=(0.9, 0.99))\n'
          '    else:\n'
          '        optimizer = torch.optim.SGD(param_configs, momentum=momentum, nesterov=True)\n'
          '\n'
          '    def get_lr(step):\n'
          '        warmup_steps = int(total_train_steps * 0.23)\n'
          '        warmdown_steps = total_train_steps - warmup_steps\n'
          '        if step < warmup_steps:\n'
          '            frac = step / warmup_steps\n'
          '            return 0.2 * (1 - frac) + 1.0 * frac\n'
          '        else:\n'
          '            frac = (step - warmup_steps) / warmdown_steps\n'
          '            return 1.0 * (1 - frac) + 0.07 * frac\n'
          '    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, get_lr)\n'
          '\n'
          '    alpha_schedule = 0.95**5 * (torch.arange(total_train_steps+1) / '
          'total_train_steps)**3\n'
          '    \n'
          '    # Conditional Lookahead Initialization\n'
          '    lookahead_state = LookaheadState(model) if use_lookahead else None\n'
          '\n'
          '    starter = torch.cuda.Event(enable_timing=True)\n'
          '    ender = torch.cuda.Event(enable_timing=True)\n'
          '    total_time_seconds = 0.0\n'
          '\n'
          '    # Initialize whitening\n'
          '    starter.record()\n'
          '    train_images = train_loader.normalize(train_loader.images[:5000])\n'
          '    init_whitening_conv(model[0], train_images)\n'
          '    ender.record()\n'
          '    torch.cuda.synchronize()\n'
          '    total_time_seconds += 1e-3 * starter.elapsed_time(ender)\n'
          '\n'
          '    for epoch in range(ceil(epochs)):\n'
          "        model[0].bias.requires_grad = (epoch < hyp['opt']['whiten_bias_epochs'])\n"
          '\n'
          '        ####################\n'
          '        #     Training     #\n'
          '        ####################\n'
          '\n'
          '        starter.record()\n'
          '        model.train()\n'
          '        for inputs, labels in train_loader:\n'
          '            outputs = model(inputs)\n'
          '            loss = loss_fn(outputs, labels).sum()\n'
          '            optimizer.zero_grad(set_to_none=True)\n'
          '            loss.backward()\n'
          '            optimizer.step()\n'
          '            scheduler.step()\n'
          '\n'
          '            current_steps += 1\n'
          '\n'
          '            # Conditional Lookahead Update\n'
          '            if use_lookahead and current_steps % 5 == 0:\n'
          '                lookahead_state.update(model, '
          'decay=alpha_schedule[current_steps].item())\n'
          '\n'
          '            if current_steps >= total_train_steps:\n'
          '                # Conditional Lookahead Final Sync\n'
          '                if use_lookahead:\n'
          '                    lookahead_state.update(model, decay=1.0)\n'
          '                break\n'
          '\n'
          '        ender.record()\n'
          '        torch.cuda.synchronize()\n'
          '        total_time_seconds += 1e-3 * starter.elapsed_time(ender)\n'
          '\n'
          '        ####################\n'
          '        #    Evaluation    #\n'
          '        ####################\n'
          '\n'
          '        train_acc = (outputs.detach().argmax(1) == labels).float().mean().item()\n'
          '        train_loss = loss.item() / batch_size\n'
          '        val_acc = evaluate(model, test_loader, tta_level=0)\n'
          '        # Log mode along with stats\n'
          '        print_training_details(locals(), is_final_entry=False)\n'
          '        run = None \n'
          '\n'
          '    ####################\n'
          '    #  TTA Evaluation  #\n'
          '    ####################\n'
          '\n'
          '    starter.record()\n'
          "    tta_val_acc = evaluate(model, test_loader, tta_level=hyp['net']['tta_level'])\n"
          '    ender.record()\n'
          '    torch.cuda.synchronize()\n'
          '    total_time_seconds += 1e-3 * starter.elapsed_time(ender)\n'
          '\n'
          "    epoch = 'eval'\n"
          '    print_training_details(locals(), is_final_entry=True)\n'
          '\n'
          '    return tta_val_acc, total_time_seconds\n'
          '\n'
          'if __name__ == "__main__":\n'
          "    parser = argparse.ArgumentParser(description='CIFAR-10 Speedrun Experiments')\n"
          "    parser.add_argument('--mode', type=str, default='baseline', \n"
          "                        choices=['baseline', 'lion', 'lion_lookahead', 'hardswish'],\n"
          "                        help='Experiment mode: baseline, lion, lion_lookahead, or "
          "hardswish')\n"
          "    parser.add_argument('--runs', type=int, default=5, help='Number of runs to "
          "perform')\n"
          '    args = parser.parse_args()\n'
          '\n'
          '    with open(sys.argv[0]) as f:\n'
          '        code = f.read()\n'
          '\n'
          '    print(f"Running Experiment Mode: {args.mode}")\n'
          '    print_columns(logging_columns_list, is_head=True)\n'
          '    \n'
          '    # ------------------\n'
          '    # Warmup Run Added\n'
          '    # ------------------\n'
          '    print("Performing warmup run...")\n'
          "    # We pass 'warmup' as the run identifier. \n"
          '    # The return values are ignored.\n'
          "    main('warmup', args)\n"
          '    print("Warmup complete. Starting measured runs.")\n'
          "    print('-' * 100) # Visual separator\n"
          '    \n'
          '    # Collect results\n'
          '    results = []\n'
          '    times = []\n'
          '    for run in range(args.runs):\n'
          '        acc, time = main(run, args)\n'
          '        results.append(acc)\n'
          '        times.append(time)\n'
          '    \n'
          '    accs = torch.tensor(results)\n'
          '    times_t = torch.tensor(times)\n'
          '    \n'
          "    print(f'\\nSummary for {args.mode}:')\n"
          "    print('Accuracy - Mean: %.4f    Std: %.4f' % (accs.mean(), accs.std()))\n"
          "    print('Time     - Mean: %.4f    Std: %.4f' % (times_t.mean(), times_t.std()))\n"
          '\n'
          '    log = {\n'
          "        'code': code, \n"
          "        'accs': accs, \n"
          "        'times': times_t,\n"
          "        'mode': args.mode,\n"
          "        'hyp': hyp\n"
          '    }\n'
          "    log_dir = os.path.join('logs', str(uuid.uuid4()))\n"
          '    os.makedirs(log_dir, exist_ok=True)\n'
          "    log_path = os.path.join(log_dir, 'log.pt')\n"
          '    print(os.path.abspath(log_path))\n'
          '    torch.save(log, log_path)',
  'hyp': { 'aug': {'flip': True, 'translate': 2},
           'net': { 'batchnorm_momentum': 0.6,
                    'scaling_factor': 0.1111111111111111,
                    'tta_level': 2,
                    'widths': {'block1': 64, 'block2': 256, 'block3': 256}},
           'opt': { 'batch_size': 1024,
                    'bias_scaler': 64.0,
                    'label_smoothing': 0.2,
                    'lr': 11.5,
                    'momentum': 0.85,
                    'train_epochs': 9.9,
                    'weight_decay': 0.0153,
                    'whiten_bias_epochs': 3}},
  'mode': 'lion',
  'times': tensor([4.1581, 4.1657, 4.1688, 4.1707, 4.1729])}